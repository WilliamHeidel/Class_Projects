{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbJiCHZHBJ-x"
   },
   "source": [
    "# CS342: Colab Template\n",
    "\n",
    "This is the verbose version of the notebook you will using, if you choose to use Colab to train.  \n",
    "\n",
    "We recommend you edit all the information and save your own copy which you can use for all the homeworks.\n",
    "\n",
    "## 1. Set up the GPU\n",
    "\n",
    "First, make sure your colab has access to a GPU.  \n",
    "Select Runtime -> Change runtime type > GPU.\n",
    "\n",
    "Check to see if this works by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3485,
     "status": "ok",
     "timestamp": 1733236294016,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "wazOTw_BxBhl",
    "outputId": "2482ba17-841a-4e94-e168-d7f8ef696229"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJ6a2n73xU4-"
   },
   "source": [
    "## 2. Sync your code to Colab\n",
    "\n",
    "Set up a **private** GitHub repo with your homework and name it `cs342`.  \n",
    "Never use a public repo for your homework, it may lead to plagiarism and you failing the homework and/or class.  \n",
    "\n",
    "The directory structure should look like the following -\n",
    "\n",
    "\n",
    "```\n",
    "|- cs342/\n",
    "  |- homework1\n",
    "    |- homework/\n",
    "      |- train.py\n",
    "      |- ...\n",
    "    |- grader/\n",
    "    |- ...\n",
    "  |- homework2\n",
    "    |- ...\n",
    "```\n",
    "\n",
    "Clone this by putting in your information and running the following cell.  \n",
    "\n",
    "For users with 2FA, create a new personal access token at  \n",
    "https://github.com/settings/tokens/new  \n",
    "Select repo and generate your token.  \n",
    "Then enter your personal access token as your password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16940,
     "status": "ok",
     "timestamp": 1733236310952,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "aOfaBRyuypz3",
    "outputId": "687ed696-566d-4c47-d042-04db25e8f85e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dsc388'...\n",
      "remote: Enumerating objects: 1400, done.\u001b[K\n",
      "remote: Counting objects: 100% (275/275), done.\u001b[K\n",
      "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
      "remote: Total 1400 (delta 149), reused 268 (delta 145), pack-reused 1125 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1400/1400), 414.74 MiB | 44.01 MiB/s, done.\n",
      "Resolving deltas: 100% (903/903), done.\n",
      "/content/dsc388\n",
      "Updating files: 100% (244/244), done.\n",
      "Branch 'final_project_testing' set up to track remote branch 'final_project_testing' from 'origin'.\n",
      "Switched to a new branch 'final_project_testing'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ['USER'] = 'WilliamHeidel'\n",
    "os.environ['PASS'] = userdata.get('GIT_PASSCODE')\n",
    "os.environ['REPO'] = 'dsc388'\n",
    "\n",
    "#!git@github.com:WilliamHeidel/cs342.git\n",
    "!git clone https://$USER:$PASS@github.com/$USER/$REPO.git\n",
    "\n",
    "%cd dsc388\n",
    "!git checkout final_project_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OERNtax88uAN"
   },
   "source": [
    "## 3. Prepare the data.\n",
    "\n",
    "Run the following cell to download and unzip the dataset.  \n",
    "\n",
    "Make sure you see the `homework`, `grader`, `data` directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733236310953,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "mA3FHtOhtFHH",
    "outputId": "91eb13e3-8196-4aab-838f-c02940460ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/dsc388/Final Project/Repo\n"
     ]
    }
   ],
   "source": [
    "%cd \"Final Project/Repo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19868,
     "status": "ok",
     "timestamp": 1733236330818,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "SObt1dAZ9JDV",
    "outputId": "c491d291-2356-48c5-e1fb-87850d969a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-24.3.1\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.1.1)\n",
      "Collecting datasets (from -r requirements.txt (line 2))\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.66.6)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.46.2)\n",
      "Collecting evaluate (from -r requirements.txt (line 6))\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.7.5)\n",
      "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.26.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 2))\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (2.32.3)\n",
      "Collecting xxhash (from datasets->-r requirements.txt (line 2))\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 2))\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->-r requirements.txt (line 2))\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 2)) (3.11.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.20.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (0.13.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (2.9.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (75.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->-r requirements.txt (line 7)) (3.4.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->-r requirements.txt (line 8)) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->-r requirements.txt (line 8)) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->-r requirements.txt (line 8)) (11.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 7)) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 2)) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 7)) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 7)) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 7)) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 7)) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 2)) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 7)) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 7)) (0.1.2)\n",
      "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ36HtNTCaDG"
   },
   "source": [
    "## 5. Train your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1732677046274,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "9kC0853zq-E6",
    "outputId": "723f0aff-bbbd-42e5-a9dd-77e3d382a384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1461197,
     "status": "ok",
     "timestamp": 1733237801566,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "h0uzT7P77wvU",
    "outputId": "53c46504-a8a0-4efe-d1f1-21e7cc9ac587"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 14:32:28.674138: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-03 14:32:28.690337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-03 14:32:28.711445: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-03 14:32:28.718232: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 14:32:28.733560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 14:32:29.969414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "README.md: 100% 7.62k/7.62k [00:00<00:00, 43.9MB/s]\n",
      "train-00000-of-00001.parquet: 100% 14.5M/14.5M [00:00<00:00, 110MB/s] \n",
      "validation-00000-of-00001.parquet: 100% 1.82M/1.82M [00:00<00:00, 266MB/s]\n",
      "Generating train split: 100% 87599/87599 [00:00<00:00, 411806.72 examples/s]\n",
      "Generating validation split: 100% 10570/10570 [00:00<00:00, 452053.52 examples/s]\n",
      "config.json: 100% 665/665 [00:00<00:00, 5.21MB/s]\n",
      "pytorch_model.bin: 100% 54.2M/54.2M [00:00<00:00, 94.1MB/s]\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 403kB/s]\n",
      "vocab.txt: 100% 232k/232k [00:00<00:00, 2.55MB/s]\n",
      "tokenizer.json: 100% 466k/466k [00:00<00:00, 10.6MB/s]\n",
      "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
      "README.md: 100% 8.54k/8.54k [00:00<00:00, 35.6MB/s]\n",
      "squad_adversarial.py: 100% 5.74k/5.74k [00:00<00:00, 23.5MB/s]\n",
      "Downloading data: 4.07MB [00:00, 37.6MB/s]\n",
      "Downloading data: 1.92MB [00:00, 22.8MB/s]\n",
      "Generating validation split: 100% 3560/3560 [00:00<00:00, 10688.35 examples/s]\n",
      "Map (num_proc=2): 100% 91159/91159 [00:43<00:00, 2115.92 examples/s]\n",
      "Map (num_proc=2): 100% 10570/10570 [00:05<00:00, 1853.76 examples/s]\n",
      "Downloading builder script: 100% 4.53k/4.53k [00:00<00:00, 13.1MB/s]\n",
      "Downloading extra modules: 100% 3.32k/3.32k [00:00<00:00, 17.7MB/s]\n",
      "\n",
      "Beginning Pipeline!\n",
      "\n",
      "/content/dsc388/Final Project/Repo/helpers.py:277: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "\n",
      "Beginning Evaluation!\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/dsc388/Final Project/Repo/wandb/run-20241203_143349-cclbecvq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./trained_model_final2/\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface/runs/cclbecvq\u001b[0m\n",
      "{'loss': 2.3453, 'grad_norm': 6.053024768829346, 'learning_rate': 3.832866479925304e-05, 'epoch': 0.7}\n",
      "{'loss': 1.351, 'grad_norm': 5.123288154602051, 'learning_rate': 2.665732959850607e-05, 'epoch': 1.4}\n",
      "{'loss': 1.1904, 'grad_norm': 6.387844085693359, 'learning_rate': 1.4985994397759103e-05, 'epoch': 2.1}\n",
      "{'loss': 1.0909, 'grad_norm': 7.305608749389648, 'learning_rate': 3.3146591970121383e-06, 'epoch': 2.8}\n",
      "{'train_runtime': 1301.596, 'train_samples_per_second': 210.445, 'train_steps_per_second': 1.646, 'train_loss': 1.4669796527823369, 'epoch': 3.0}\n",
      "100% 2142/2142 [21:28<00:00,  1.66it/s]\n",
      "100% 1329/1329 [00:39<00:00, 46.05it/s]\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\n",
      "  0% 50/10570 [00:00<00:21, 496.77it/s]\u001b[A\n",
      "  1% 106/10570 [00:00<00:19, 529.28it/s]\u001b[A\n",
      "  2% 161/10570 [00:00<00:19, 537.12it/s]\u001b[A\n",
      "  2% 215/10570 [00:00<00:19, 535.69it/s]\u001b[A\n",
      "  3% 269/10570 [00:00<00:20, 510.56it/s]\u001b[A\n",
      "  3% 322/10570 [00:00<00:19, 515.48it/s]\u001b[A\n",
      "  4% 377/10570 [00:00<00:19, 526.14it/s]\u001b[A\n",
      "  4% 430/10570 [00:00<00:19, 526.08it/s]\u001b[A\n",
      "  5% 483/10570 [00:00<00:19, 525.82it/s]\u001b[A\n",
      "  5% 538/10570 [00:01<00:18, 531.54it/s]\u001b[A\n",
      "  6% 592/10570 [00:01<00:18, 531.19it/s]\u001b[A\n",
      "  6% 647/10570 [00:01<00:18, 534.01it/s]\u001b[A\n",
      "  7% 701/10570 [00:01<00:18, 532.68it/s]\u001b[A\n",
      "  7% 755/10570 [00:01<00:18, 530.65it/s]\u001b[A\n",
      "  8% 809/10570 [00:01<00:18, 520.41it/s]\u001b[A\n",
      "  8% 862/10570 [00:01<00:18, 520.07it/s]\u001b[A\n",
      "  9% 915/10570 [00:01<00:18, 517.34it/s]\u001b[A\n",
      "  9% 967/10570 [00:01<00:18, 515.07it/s]\u001b[A\n",
      " 10% 1019/10570 [00:01<00:18, 513.82it/s]\u001b[A\n",
      " 10% 1071/10570 [00:02<00:18, 511.46it/s]\u001b[A\n",
      " 11% 1123/10570 [00:02<00:18, 512.61it/s]\u001b[A\n",
      " 11% 1178/10570 [00:02<00:17, 521.91it/s]\u001b[A\n",
      " 12% 1232/10570 [00:02<00:17, 525.36it/s]\u001b[A\n",
      " 12% 1285/10570 [00:02<00:17, 525.14it/s]\u001b[A\n",
      " 13% 1339/10570 [00:02<00:17, 526.82it/s]\u001b[A\n",
      " 13% 1392/10570 [00:02<00:17, 523.49it/s]\u001b[A\n",
      " 14% 1445/10570 [00:02<00:17, 524.00it/s]\u001b[A\n",
      " 14% 1499/10570 [00:02<00:17, 528.74it/s]\u001b[A\n",
      " 15% 1552/10570 [00:02<00:17, 526.96it/s]\u001b[A\n",
      " 15% 1607/10570 [00:03<00:16, 531.85it/s]\u001b[A\n",
      " 16% 1661/10570 [00:03<00:16, 533.59it/s]\u001b[A\n",
      " 16% 1716/10570 [00:03<00:16, 537.39it/s]\u001b[A\n",
      " 17% 1770/10570 [00:03<00:16, 535.51it/s]\u001b[A\n",
      " 17% 1824/10570 [00:03<00:16, 535.89it/s]\u001b[A\n",
      " 18% 1878/10570 [00:03<00:16, 535.73it/s]\u001b[A\n",
      " 18% 1933/10570 [00:03<00:16, 538.17it/s]\u001b[A\n",
      " 19% 1987/10570 [00:03<00:15, 537.19it/s]\u001b[A\n",
      " 19% 2041/10570 [00:03<00:15, 535.31it/s]\u001b[A\n",
      " 20% 2096/10570 [00:03<00:15, 538.15it/s]\u001b[A\n",
      " 20% 2150/10570 [00:04<00:16, 510.43it/s]\u001b[A\n",
      " 21% 2202/10570 [00:04<00:16, 493.04it/s]\u001b[A\n",
      " 21% 2256/10570 [00:04<00:16, 503.83it/s]\u001b[A\n",
      " 22% 2309/10570 [00:04<00:16, 511.06it/s]\u001b[A\n",
      " 22% 2363/10570 [00:04<00:15, 517.35it/s]\u001b[A\n",
      " 23% 2415/10570 [00:04<00:15, 516.12it/s]\u001b[A\n",
      " 23% 2467/10570 [00:04<00:15, 515.92it/s]\u001b[A\n",
      " 24% 2519/10570 [00:04<00:15, 514.11it/s]\u001b[A\n",
      " 24% 2571/10570 [00:04<00:15, 509.84it/s]\u001b[A\n",
      " 25% 2623/10570 [00:05<00:15, 510.24it/s]\u001b[A\n",
      " 25% 2675/10570 [00:05<00:15, 495.72it/s]\u001b[A\n",
      " 26% 2728/10570 [00:05<00:15, 503.33it/s]\u001b[A\n",
      " 26% 2783/10570 [00:05<00:15, 515.30it/s]\u001b[A\n",
      " 27% 2837/10570 [00:05<00:14, 521.15it/s]\u001b[A\n",
      " 27% 2890/10570 [00:05<00:14, 520.44it/s]\u001b[A\n",
      " 28% 2943/10570 [00:05<00:14, 522.86it/s]\u001b[A\n",
      " 28% 2996/10570 [00:05<00:14, 521.27it/s]\u001b[A\n",
      " 29% 3049/10570 [00:05<00:14, 522.17it/s]\u001b[A\n",
      " 29% 3102/10570 [00:05<00:14, 521.67it/s]\u001b[A\n",
      " 30% 3155/10570 [00:06<00:14, 520.68it/s]\u001b[A\n",
      " 30% 3208/10570 [00:06<00:14, 521.80it/s]\u001b[A\n",
      " 31% 3261/10570 [00:06<00:14, 519.48it/s]\u001b[A\n",
      " 31% 3314/10570 [00:06<00:13, 522.35it/s]\u001b[A\n",
      " 32% 3367/10570 [00:06<00:13, 523.30it/s]\u001b[A\n",
      " 32% 3420/10570 [00:06<00:13, 522.73it/s]\u001b[A\n",
      " 33% 3473/10570 [00:06<00:13, 523.53it/s]\u001b[A\n",
      " 33% 3526/10570 [00:06<00:13, 524.23it/s]\u001b[A\n",
      " 34% 3579/10570 [00:06<00:13, 519.81it/s]\u001b[A\n",
      " 34% 3631/10570 [00:06<00:13, 519.22it/s]\u001b[A\n",
      " 35% 3683/10570 [00:07<00:13, 515.69it/s]\u001b[A\n",
      " 35% 3735/10570 [00:07<00:13, 514.82it/s]\u001b[A\n",
      " 36% 3788/10570 [00:07<00:13, 517.83it/s]\u001b[A\n",
      " 36% 3841/10570 [00:07<00:12, 519.84it/s]\u001b[A\n",
      " 37% 3893/10570 [00:07<00:12, 518.73it/s]\u001b[A\n",
      " 37% 3946/10570 [00:07<00:12, 520.84it/s]\u001b[A\n",
      " 38% 3999/10570 [00:07<00:12, 521.54it/s]\u001b[A\n",
      " 38% 4052/10570 [00:07<00:12, 521.44it/s]\u001b[A\n",
      " 39% 4105/10570 [00:07<00:12, 515.02it/s]\u001b[A\n",
      " 39% 4157/10570 [00:08<00:13, 471.02it/s]\u001b[A\n",
      " 40% 4205/10570 [00:08<00:14, 447.19it/s]\u001b[A\n",
      " 40% 4253/10570 [00:08<00:13, 454.31it/s]\u001b[A\n",
      " 41% 4299/10570 [00:08<00:15, 406.48it/s]\u001b[A\n",
      " 41% 4342/10570 [00:08<00:15, 412.24it/s]\u001b[A\n",
      " 42% 4394/10570 [00:08<00:14, 439.67it/s]\u001b[A\n",
      " 42% 4447/10570 [00:08<00:13, 463.53it/s]\u001b[A\n",
      " 43% 4499/10570 [00:08<00:12, 478.18it/s]\u001b[A\n",
      " 43% 4548/10570 [00:08<00:12, 479.42it/s]\u001b[A\n",
      " 44% 4599/10570 [00:08<00:12, 485.69it/s]\u001b[A\n",
      " 44% 4649/10570 [00:09<00:12, 487.27it/s]\u001b[A\n",
      " 44% 4699/10570 [00:09<00:11, 489.75it/s]\u001b[A\n",
      " 45% 4751/10570 [00:09<00:11, 498.37it/s]\u001b[A\n",
      " 45% 4801/10570 [00:09<00:11, 496.02it/s]\u001b[A\n",
      " 46% 4852/10570 [00:09<00:11, 498.19it/s]\u001b[A\n",
      " 46% 4903/10570 [00:09<00:11, 499.58it/s]\u001b[A\n",
      " 47% 4955/10570 [00:09<00:11, 505.34it/s]\u001b[A\n",
      " 47% 5006/10570 [00:09<00:11, 504.24it/s]\u001b[A\n",
      " 48% 5058/10570 [00:09<00:10, 507.82it/s]\u001b[A\n",
      " 48% 5110/10570 [00:09<00:10, 509.89it/s]\u001b[A\n",
      " 49% 5162/10570 [00:10<00:10, 508.70it/s]\u001b[A\n",
      " 49% 5214/10570 [00:10<00:10, 511.18it/s]\u001b[A\n",
      " 50% 5267/10570 [00:10<00:10, 514.35it/s]\u001b[A\n",
      " 50% 5321/10570 [00:10<00:10, 520.18it/s]\u001b[A\n",
      " 51% 5374/10570 [00:10<00:09, 520.12it/s]\u001b[A\n",
      " 51% 5427/10570 [00:10<00:09, 519.79it/s]\u001b[A\n",
      " 52% 5479/10570 [00:10<00:09, 511.57it/s]\u001b[A\n",
      " 52% 5531/10570 [00:10<00:09, 507.54it/s]\u001b[A\n",
      " 53% 5583/10570 [00:10<00:09, 510.03it/s]\u001b[A\n",
      " 53% 5635/10570 [00:11<00:09, 511.63it/s]\u001b[A\n",
      " 54% 5687/10570 [00:11<00:09, 511.52it/s]\u001b[A\n",
      " 54% 5739/10570 [00:11<00:09, 513.90it/s]\u001b[A\n",
      " 55% 5791/10570 [00:11<00:09, 510.98it/s]\u001b[A\n",
      " 55% 5844/10570 [00:11<00:09, 513.86it/s]\u001b[A\n",
      " 56% 5896/10570 [00:11<00:09, 514.74it/s]\u001b[A\n",
      " 56% 5948/10570 [00:11<00:08, 514.55it/s]\u001b[A\n",
      " 57% 6000/10570 [00:11<00:08, 515.78it/s]\u001b[A\n",
      " 57% 6052/10570 [00:11<00:08, 507.73it/s]\u001b[A\n",
      " 58% 6103/10570 [00:11<00:08, 504.80it/s]\u001b[A\n",
      " 58% 6156/10570 [00:12<00:08, 509.27it/s]\u001b[A\n",
      " 59% 6207/10570 [00:12<00:08, 496.23it/s]\u001b[A\n",
      " 59% 6258/10570 [00:12<00:08, 498.70it/s]\u001b[A\n",
      " 60% 6311/10570 [00:12<00:08, 507.85it/s]\u001b[A\n",
      " 60% 6363/10570 [00:12<00:08, 510.77it/s]\u001b[A\n",
      " 61% 6415/10570 [00:12<00:08, 497.16it/s]\u001b[A\n",
      " 61% 6468/10570 [00:12<00:08, 506.32it/s]\u001b[A\n",
      " 62% 6520/10570 [00:12<00:07, 509.11it/s]\u001b[A\n",
      " 62% 6572/10570 [00:12<00:07, 511.84it/s]\u001b[A\n",
      " 63% 6624/10570 [00:12<00:07, 510.37it/s]\u001b[A\n",
      " 63% 6676/10570 [00:13<00:07, 497.71it/s]\u001b[A\n",
      " 64% 6726/10570 [00:13<00:08, 476.97it/s]\u001b[A\n",
      " 64% 6777/10570 [00:13<00:07, 484.37it/s]\u001b[A\n",
      " 65% 6828/10570 [00:13<00:07, 491.15it/s]\u001b[A\n",
      " 65% 6879/10570 [00:13<00:07, 495.92it/s]\u001b[A\n",
      " 66% 6931/10570 [00:13<00:07, 500.28it/s]\u001b[A\n",
      " 66% 6984/10570 [00:13<00:07, 506.65it/s]\u001b[A\n",
      " 67% 7037/10570 [00:13<00:06, 513.01it/s]\u001b[A\n",
      " 67% 7090/10570 [00:13<00:06, 515.63it/s]\u001b[A\n",
      " 68% 7143/10570 [00:13<00:06, 518.97it/s]\u001b[A\n",
      " 68% 7196/10570 [00:14<00:06, 519.40it/s]\u001b[A\n",
      " 69% 7248/10570 [00:14<00:06, 516.06it/s]\u001b[A\n",
      " 69% 7300/10570 [00:14<00:06, 516.24it/s]\u001b[A\n",
      " 70% 7352/10570 [00:14<00:06, 509.19it/s]\u001b[A\n",
      " 70% 7404/10570 [00:14<00:06, 509.99it/s]\u001b[A\n",
      " 71% 7457/10570 [00:14<00:06, 513.81it/s]\u001b[A\n",
      " 71% 7510/10570 [00:14<00:05, 516.34it/s]\u001b[A\n",
      " 72% 7562/10570 [00:14<00:05, 517.33it/s]\u001b[A\n",
      " 72% 7614/10570 [00:14<00:05, 517.86it/s]\u001b[A\n",
      " 73% 7666/10570 [00:15<00:05, 508.23it/s]\u001b[A\n",
      " 73% 7717/10570 [00:15<00:05, 507.35it/s]\u001b[A\n",
      " 73% 7768/10570 [00:15<00:05, 507.84it/s]\u001b[A\n",
      " 74% 7819/10570 [00:15<00:05, 508.44it/s]\u001b[A\n",
      " 74% 7872/10570 [00:15<00:05, 512.85it/s]\u001b[A\n",
      " 75% 7925/10570 [00:15<00:05, 515.21it/s]\u001b[A\n",
      " 75% 7977/10570 [00:15<00:05, 514.46it/s]\u001b[A\n",
      " 76% 8029/10570 [00:15<00:04, 514.89it/s]\u001b[A\n",
      " 76% 8081/10570 [00:15<00:04, 511.91it/s]\u001b[A\n",
      " 77% 8134/10570 [00:15<00:04, 514.73it/s]\u001b[A\n",
      " 77% 8186/10570 [00:16<00:04, 506.40it/s]\u001b[A\n",
      " 78% 8237/10570 [00:16<00:04, 503.88it/s]\u001b[A\n",
      " 78% 8288/10570 [00:16<00:04, 500.62it/s]\u001b[A\n",
      " 79% 8339/10570 [00:16<00:04, 501.17it/s]\u001b[A\n",
      " 79% 8392/10570 [00:16<00:04, 509.12it/s]\u001b[A\n",
      " 80% 8445/10570 [00:16<00:04, 513.02it/s]\u001b[A\n",
      " 80% 8498/10570 [00:16<00:04, 516.16it/s]\u001b[A\n",
      " 81% 8550/10570 [00:16<00:03, 516.47it/s]\u001b[A\n",
      " 81% 8603/10570 [00:16<00:03, 517.83it/s]\u001b[A\n",
      " 82% 8655/10570 [00:16<00:03, 517.18it/s]\u001b[A\n",
      " 82% 8708/10570 [00:17<00:03, 518.67it/s]\u001b[A\n",
      " 83% 8760/10570 [00:17<00:03, 516.46it/s]\u001b[A\n",
      " 83% 8812/10570 [00:17<00:03, 510.71it/s]\u001b[A\n",
      " 84% 8864/10570 [00:17<00:03, 512.85it/s]\u001b[A\n",
      " 84% 8916/10570 [00:17<00:03, 514.57it/s]\u001b[A\n",
      " 85% 8968/10570 [00:17<00:03, 516.02it/s]\u001b[A\n",
      " 85% 9021/10570 [00:17<00:02, 518.88it/s]\u001b[A\n",
      " 86% 9073/10570 [00:17<00:02, 518.84it/s]\u001b[A\n",
      " 86% 9125/10570 [00:17<00:02, 517.85it/s]\u001b[A\n",
      " 87% 9177/10570 [00:17<00:02, 513.67it/s]\u001b[A\n",
      " 87% 9230/10570 [00:18<00:02, 515.70it/s]\u001b[A\n",
      " 88% 9283/10570 [00:18<00:02, 518.31it/s]\u001b[A\n",
      " 88% 9335/10570 [00:18<00:02, 518.10it/s]\u001b[A\n",
      " 89% 9388/10570 [00:18<00:02, 518.90it/s]\u001b[A\n",
      " 89% 9441/10570 [00:18<00:02, 521.47it/s]\u001b[A\n",
      " 90% 9494/10570 [00:18<00:02, 522.65it/s]\u001b[A\n",
      " 90% 9548/10570 [00:18<00:01, 526.29it/s]\u001b[A\n",
      " 91% 9601/10570 [00:18<00:01, 525.52it/s]\u001b[A\n",
      " 91% 9654/10570 [00:18<00:01, 526.74it/s]\u001b[A\n",
      " 92% 9708/10570 [00:18<00:01, 529.44it/s]\u001b[A\n",
      " 92% 9762/10570 [00:19<00:01, 530.49it/s]\u001b[A\n",
      " 93% 9816/10570 [00:19<00:01, 528.07it/s]\u001b[A\n",
      " 93% 9869/10570 [00:19<00:01, 522.49it/s]\u001b[A\n",
      " 94% 9922/10570 [00:19<00:01, 522.63it/s]\u001b[A\n",
      " 94% 9975/10570 [00:19<00:01, 518.79it/s]\u001b[A\n",
      " 95% 10027/10570 [00:19<00:01, 503.65it/s]\u001b[A\n",
      " 95% 10080/10570 [00:19<00:00, 509.76it/s]\u001b[A\n",
      " 96% 10133/10570 [00:19<00:00, 513.59it/s]\u001b[A\n",
      " 96% 10185/10570 [00:19<00:00, 511.79it/s]\u001b[A\n",
      " 97% 10237/10570 [00:20<00:00, 495.50it/s]\u001b[A\n",
      " 97% 10287/10570 [00:20<00:00, 479.41it/s]\u001b[A\n",
      " 98% 10336/10570 [00:20<00:00, 481.21it/s]\u001b[A\n",
      " 98% 10385/10570 [00:20<00:00, 483.01it/s]\u001b[A\n",
      " 99% 10434/10570 [00:20<00:00, 482.78it/s]\u001b[A\n",
      " 99% 10486/10570 [00:20<00:00, 491.19it/s]\u001b[A\n",
      "100% 10570/10570 [00:20<00:00, 510.90it/s]\n",
      "100% 1329/1329 [01:06<00:00, 19.92it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 75.87511825922422, 'eval_f1': 84.15939631407576, 'epoch': 3.0}\n",
      "Filter: 100% 10570/10570 [00:00<00:00, 27864.26 examples/s]\n",
      "Map (num_proc=2): 100% 870/870 [00:00<00:00, 1303.76 examples/s]\n",
      " 96% 106/110 [00:02<00:00, 46.29it/s]\n",
      "  0% 0/870 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 52/870 [00:00<00:01, 512.71it/s]\u001b[A\n",
      " 12% 104/870 [00:00<00:01, 516.81it/s]\u001b[A\n",
      " 18% 156/870 [00:00<00:01, 515.48it/s]\u001b[A\n",
      " 24% 209/870 [00:00<00:01, 518.40it/s]\u001b[A\n",
      " 30% 261/870 [00:00<00:01, 515.55it/s]\u001b[A\n",
      " 36% 314/870 [00:00<00:01, 518.15it/s]\u001b[A\n",
      " 42% 366/870 [00:00<00:00, 516.31it/s]\u001b[A\n",
      " 48% 418/870 [00:00<00:00, 500.79it/s]\u001b[A\n",
      " 54% 469/870 [00:00<00:00, 502.87it/s]\u001b[A\n",
      " 60% 520/870 [00:01<00:00, 504.98it/s]\u001b[A\n",
      " 66% 571/870 [00:01<00:00, 505.01it/s]\u001b[A\n",
      " 71% 622/870 [00:01<00:00, 505.70it/s]\u001b[A\n",
      " 77% 673/870 [00:01<00:00, 504.92it/s]\u001b[A\n",
      " 83% 725/870 [00:01<00:00, 507.03it/s]\u001b[A\n",
      " 89% 776/870 [00:01<00:00, 506.64it/s]\u001b[A\n",
      "100% 870/870 [00:01<00:00, 509.45it/s]\n",
      "100% 110/110 [00:05<00:00, 19.93it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 18.275862068965516, 'eval_f1': 24.394183900681046, 'epoch': 3.0}\n",
      "Filter: 100% 10570/10570 [00:00<00:00, 36870.90 examples/s]\n",
      "Map (num_proc=2): 100% 452/452 [00:00<00:00, 1051.53 examples/s]\n",
      " 98% 56/57 [00:01<00:00, 46.27it/s]\n",
      "  0% 0/452 [00:00<?, ?it/s]\u001b[A\n",
      " 11% 50/452 [00:00<00:00, 495.97it/s]\u001b[A\n",
      " 23% 102/452 [00:00<00:00, 506.55it/s]\u001b[A\n",
      " 34% 154/452 [00:00<00:00, 508.34it/s]\u001b[A\n",
      " 45% 205/452 [00:00<00:00, 507.65it/s]\u001b[A\n",
      " 57% 256/452 [00:00<00:00, 498.19it/s]\u001b[A\n",
      " 68% 306/452 [00:00<00:00, 493.80it/s]\u001b[A\n",
      " 79% 357/452 [00:00<00:00, 496.24it/s]\u001b[A\n",
      "100% 452/452 [00:00<00:00, 501.08it/s]\n",
      "100% 57/57 [00:02<00:00, 19.80it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 20.575221238938052, 'eval_f1': 26.22107339789197, 'epoch': 3.0}\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m./trained_model_final2/\u001b[0m at: \u001b[34mhttps://wandb.ai/billiam1100-/huggingface/runs/cclbecvq\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_143349-cclbecvq/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model_final2/ --perc_squad 1 --perc_adversarial_squad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1473531,
     "status": "ok",
     "timestamp": 1733239275094,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "0LZJRpGX71W7",
    "outputId": "df24e498-a336-4b64-8e89-b67e69dfff0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-03 14:56:45.559250: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-03 14:56:45.575884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-03 14:56:45.596583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-03 14:56:45.602828: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 14:56:45.618337: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-03 14:56:46.690128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
      "Map (num_proc=2): 100% 94719/94719 [00:44<00:00, 2105.62 examples/s]\n",
      "\n",
      "Beginning Pipeline!\n",
      "\n",
      "/content/dsc388/Final Project/Repo/helpers.py:277: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "\n",
      "Beginning Evaluation!\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbilliam1100\u001b[0m (\u001b[33mbilliam1100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/dsc388/Final Project/Repo/wandb/run-20241203_145739-siuxr8zi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./trained_model_final3/\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface/runs/siuxr8zi\u001b[0m\n",
      "{'loss': 2.3402, 'grad_norm': 6.282591819763184, 'learning_rate': 3.876909254267745e-05, 'epoch': 0.67}\n",
      "{'loss': 1.3602, 'grad_norm': 6.597254753112793, 'learning_rate': 2.75381850853549e-05, 'epoch': 1.35}\n",
      "{'loss': 1.1984, 'grad_norm': 5.180280685424805, 'learning_rate': 1.6307277628032348e-05, 'epoch': 2.02}\n",
      "{'loss': 1.086, 'grad_norm': 5.69411563873291, 'learning_rate': 5.0763701707097935e-06, 'epoch': 2.7}\n",
      "{'train_runtime': 1336.9709, 'train_samples_per_second': 212.935, 'train_steps_per_second': 1.665, 'train_loss': 1.4536104776360168, 'epoch': 3.0}\n",
      "100% 2226/2226 [22:15<00:00,  1.67it/s]\n",
      "100% 1327/1329 [00:29<00:00, 45.86it/s]\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\n",
      "  1% 54/10570 [00:00<00:19, 532.88it/s]\u001b[A\n",
      "  1% 110/10570 [00:00<00:19, 543.85it/s]\u001b[A\n",
      "  2% 165/10570 [00:00<00:19, 546.05it/s]\u001b[A\n",
      "  2% 220/10570 [00:00<00:19, 538.92it/s]\u001b[A\n",
      "  3% 274/10570 [00:00<00:20, 513.13it/s]\u001b[A\n",
      "  3% 327/10570 [00:00<00:19, 518.56it/s]\u001b[A\n",
      "  4% 381/10570 [00:00<00:19, 525.14it/s]\u001b[A\n",
      "  4% 434/10570 [00:00<00:19, 526.19it/s]\u001b[A\n",
      "100% 1329/1329 [00:44<00:00, 45.86it/s]\n",
      "  5% 541/10570 [00:01<00:18, 530.24it/s]\u001b[A\n",
      "  6% 595/10570 [00:01<00:18, 529.59it/s]\u001b[A\n",
      "  6% 650/10570 [00:01<00:18, 534.38it/s]\u001b[A\n",
      "  7% 705/10570 [00:01<00:18, 536.96it/s]\u001b[A\n",
      "  7% 759/10570 [00:01<00:18, 535.33it/s]\u001b[A\n",
      "  8% 813/10570 [00:01<00:18, 526.99it/s]\u001b[A\n",
      "  8% 866/10570 [00:01<00:18, 524.20it/s]\u001b[A\n",
      "  9% 919/10570 [00:01<00:18, 523.89it/s]\u001b[A\n",
      "  9% 972/10570 [00:01<00:18, 524.29it/s]\u001b[A\n",
      " 10% 1025/10570 [00:01<00:18, 524.08it/s]\u001b[A\n",
      " 10% 1078/10570 [00:02<00:18, 525.49it/s]\u001b[A\n",
      " 11% 1131/10570 [00:02<00:17, 524.94it/s]\u001b[A\n",
      " 11% 1186/10570 [00:02<00:17, 531.25it/s]\u001b[A\n",
      " 12% 1240/10570 [00:02<00:17, 533.66it/s]\u001b[A\n",
      " 12% 1294/10570 [00:02<00:17, 534.36it/s]\u001b[A\n",
      " 13% 1348/10570 [00:02<00:17, 530.92it/s]\u001b[A\n",
      " 13% 1402/10570 [00:02<00:17, 521.89it/s]\u001b[A\n",
      " 14% 1456/10570 [00:02<00:17, 526.17it/s]\u001b[A\n",
      " 14% 1510/10570 [00:02<00:17, 528.59it/s]\u001b[A\n",
      " 15% 1564/10570 [00:02<00:16, 531.44it/s]\u001b[A\n",
      " 15% 1618/10570 [00:03<00:16, 533.67it/s]\u001b[A\n",
      " 16% 1672/10570 [00:03<00:16, 532.30it/s]\u001b[A\n",
      " 16% 1727/10570 [00:03<00:16, 535.96it/s]\u001b[A\n",
      " 17% 1781/10570 [00:03<00:16, 532.02it/s]\u001b[A\n",
      " 17% 1835/10570 [00:03<00:16, 533.21it/s]\u001b[A\n",
      " 18% 1889/10570 [00:03<00:16, 533.80it/s]\u001b[A\n",
      " 18% 1944/10570 [00:03<00:16, 537.43it/s]\u001b[A\n",
      " 19% 1999/10570 [00:03<00:15, 538.52it/s]\u001b[A\n",
      " 19% 2053/10570 [00:03<00:15, 537.74it/s]\u001b[A\n",
      " 20% 2108/10570 [00:03<00:15, 539.12it/s]\u001b[A\n",
      " 20% 2162/10570 [00:04<00:15, 531.49it/s]\u001b[A\n",
      " 21% 2216/10570 [00:04<00:15, 528.74it/s]\u001b[A\n",
      " 21% 2270/10570 [00:04<00:15, 529.34it/s]\u001b[A\n",
      " 22% 2323/10570 [00:04<00:15, 525.97it/s]\u001b[A\n",
      " 22% 2377/10570 [00:04<00:15, 527.93it/s]\u001b[A\n",
      " 23% 2430/10570 [00:04<00:15, 526.73it/s]\u001b[A\n",
      " 23% 2483/10570 [00:04<00:15, 525.72it/s]\u001b[A\n",
      " 24% 2536/10570 [00:04<00:15, 521.42it/s]\u001b[A\n",
      " 24% 2589/10570 [00:04<00:15, 519.29it/s]\u001b[A\n",
      " 25% 2643/10570 [00:04<00:15, 523.49it/s]\u001b[A\n",
      " 26% 2696/10570 [00:05<00:14, 524.94it/s]\u001b[A\n",
      " 26% 2750/10570 [00:05<00:14, 528.99it/s]\u001b[A\n",
      " 27% 2805/10570 [00:05<00:14, 534.34it/s]\u001b[A\n",
      " 27% 2859/10570 [00:05<00:14, 533.99it/s]\u001b[A\n",
      " 28% 2913/10570 [00:05<00:14, 530.45it/s]\u001b[A\n",
      " 28% 2967/10570 [00:05<00:14, 529.70it/s]\u001b[A\n",
      " 29% 3021/10570 [00:05<00:14, 530.16it/s]\u001b[A\n",
      " 29% 3075/10570 [00:05<00:14, 530.33it/s]\u001b[A\n",
      " 30% 3129/10570 [00:05<00:14, 530.86it/s]\u001b[A\n",
      " 30% 3183/10570 [00:06<00:14, 525.39it/s]\u001b[A\n",
      " 31% 3236/10570 [00:06<00:14, 523.34it/s]\u001b[A\n",
      " 31% 3289/10570 [00:06<00:13, 525.01it/s]\u001b[A\n",
      " 32% 3343/10570 [00:06<00:13, 527.12it/s]\u001b[A\n",
      " 32% 3396/10570 [00:06<00:13, 524.81it/s]\u001b[A\n",
      " 33% 3449/10570 [00:06<00:13, 524.72it/s]\u001b[A\n",
      " 33% 3502/10570 [00:06<00:13, 517.54it/s]\u001b[A\n",
      " 34% 3554/10570 [00:06<00:14, 496.90it/s]\u001b[A\n",
      " 34% 3604/10570 [00:06<00:14, 493.24it/s]\u001b[A\n",
      " 35% 3658/10570 [00:06<00:13, 504.62it/s]\u001b[A\n",
      " 35% 3711/10570 [00:07<00:13, 511.12it/s]\u001b[A\n",
      " 36% 3763/10570 [00:07<00:13, 513.09it/s]\u001b[A\n",
      " 36% 3816/10570 [00:07<00:13, 515.80it/s]\u001b[A\n",
      " 37% 3869/10570 [00:07<00:12, 519.62it/s]\u001b[A\n",
      " 37% 3922/10570 [00:07<00:12, 520.58it/s]\u001b[A\n",
      " 38% 3975/10570 [00:07<00:12, 523.12it/s]\u001b[A\n",
      " 38% 4028/10570 [00:07<00:12, 523.11it/s]\u001b[A\n",
      " 39% 4081/10570 [00:07<00:12, 524.52it/s]\u001b[A\n",
      " 39% 4134/10570 [00:07<00:12, 513.58it/s]\u001b[A\n",
      " 40% 4186/10570 [00:08<00:13, 457.10it/s]\u001b[A\n",
      " 40% 4233/10570 [00:08<00:14, 450.56it/s]\u001b[A\n",
      " 40% 4279/10570 [00:08<00:14, 427.67it/s]\u001b[A\n",
      " 41% 4323/10570 [00:08<00:15, 405.87it/s]\u001b[A\n",
      " 41% 4376/10570 [00:08<00:14, 436.87it/s]\u001b[A\n",
      " 42% 4429/10570 [00:08<00:13, 460.50it/s]\u001b[A\n",
      " 42% 4482/10570 [00:08<00:12, 479.35it/s]\u001b[A\n",
      " 43% 4531/10570 [00:08<00:13, 458.55it/s]\u001b[A\n",
      " 43% 4578/10570 [00:08<00:13, 454.68it/s]\u001b[A\n",
      " 44% 4627/10570 [00:08<00:12, 463.71it/s]\u001b[A\n",
      " 44% 4676/10570 [00:09<00:12, 470.11it/s]\u001b[A\n",
      " 45% 4729/10570 [00:09<00:12, 486.59it/s]\u001b[A\n",
      " 45% 4779/10570 [00:09<00:11, 488.66it/s]\u001b[A\n",
      " 46% 4832/10570 [00:09<00:11, 499.26it/s]\u001b[A\n",
      " 46% 4883/10570 [00:09<00:11, 491.28it/s]\u001b[A\n",
      " 47% 4936/10570 [00:09<00:11, 500.05it/s]\u001b[A\n",
      " 47% 4988/10570 [00:09<00:11, 502.90it/s]\u001b[A\n",
      " 48% 5039/10570 [00:09<00:11, 500.55it/s]\u001b[A\n",
      " 48% 5091/10570 [00:09<00:10, 504.56it/s]\u001b[A\n",
      " 49% 5144/10570 [00:10<00:10, 510.21it/s]\u001b[A\n",
      " 49% 5196/10570 [00:10<00:10, 509.43it/s]\u001b[A\n",
      " 50% 5247/10570 [00:10<00:10, 507.13it/s]\u001b[A\n",
      " 50% 5301/10570 [00:10<00:10, 515.45it/s]\u001b[A\n",
      " 51% 5354/10570 [00:10<00:10, 519.03it/s]\u001b[A\n",
      " 51% 5406/10570 [00:10<00:10, 512.26it/s]\u001b[A\n",
      " 52% 5458/10570 [00:10<00:10, 510.73it/s]\u001b[A\n",
      " 52% 5510/10570 [00:10<00:09, 507.69it/s]\u001b[A\n",
      " 53% 5561/10570 [00:10<00:09, 502.74it/s]\u001b[A\n",
      " 53% 5612/10570 [00:10<00:09, 502.74it/s]\u001b[A\n",
      " 54% 5663/10570 [00:11<00:09, 492.49it/s]\u001b[A\n",
      " 54% 5715/10570 [00:11<00:09, 500.03it/s]\u001b[A\n",
      " 55% 5767/10570 [00:11<00:09, 503.87it/s]\u001b[A\n",
      " 55% 5819/10570 [00:11<00:09, 506.26it/s]\u001b[A\n",
      " 56% 5871/10570 [00:11<00:09, 509.71it/s]\u001b[A\n",
      " 56% 5923/10570 [00:11<00:09, 511.18it/s]\u001b[A\n",
      " 57% 5976/10570 [00:11<00:08, 514.98it/s]\u001b[A\n",
      " 57% 6028/10570 [00:11<00:08, 514.95it/s]\u001b[A\n",
      " 58% 6080/10570 [00:11<00:08, 509.02it/s]\u001b[A\n",
      " 58% 6132/10570 [00:11<00:08, 509.76it/s]\u001b[A\n",
      " 59% 6185/10570 [00:12<00:08, 514.61it/s]\u001b[A\n",
      " 59% 6237/10570 [00:12<00:08, 510.41it/s]\u001b[A\n",
      " 59% 6289/10570 [00:12<00:08, 512.75it/s]\u001b[A\n",
      " 60% 6342/10570 [00:12<00:08, 516.53it/s]\u001b[A\n",
      " 60% 6394/10570 [00:12<00:08, 496.29it/s]\u001b[A\n",
      " 61% 6448/10570 [00:12<00:08, 507.51it/s]\u001b[A\n",
      " 61% 6500/10570 [00:12<00:07, 510.98it/s]\u001b[A\n",
      " 62% 6553/10570 [00:12<00:07, 514.85it/s]\u001b[A\n",
      " 62% 6605/10570 [00:12<00:07, 515.52it/s]\u001b[A\n",
      " 63% 6658/10570 [00:12<00:07, 519.49it/s]\u001b[A\n",
      " 63% 6710/10570 [00:13<00:07, 517.83it/s]\u001b[A\n",
      " 64% 6763/10570 [00:13<00:07, 521.21it/s]\u001b[A\n",
      " 64% 6816/10570 [00:13<00:07, 519.17it/s]\u001b[A\n",
      " 65% 6868/10570 [00:13<00:07, 516.28it/s]\u001b[A\n",
      " 65% 6920/10570 [00:13<00:07, 516.81it/s]\u001b[A\n",
      " 66% 6972/10570 [00:13<00:06, 516.06it/s]\u001b[A\n",
      " 66% 7025/10570 [00:13<00:06, 519.66it/s]\u001b[A\n",
      " 67% 7078/10570 [00:13<00:06, 521.03it/s]\u001b[A\n",
      " 67% 7131/10570 [00:13<00:06, 522.53it/s]\u001b[A\n",
      " 68% 7184/10570 [00:13<00:06, 523.31it/s]\u001b[A\n",
      " 68% 7237/10570 [00:14<00:06, 518.39it/s]\u001b[A\n",
      " 69% 7289/10570 [00:14<00:06, 518.36it/s]\u001b[A\n",
      " 69% 7341/10570 [00:14<00:06, 512.32it/s]\u001b[A\n",
      " 70% 7394/10570 [00:14<00:06, 516.60it/s]\u001b[A\n",
      " 70% 7446/10570 [00:14<00:06, 515.23it/s]\u001b[A\n",
      " 71% 7498/10570 [00:14<00:06, 503.16it/s]\u001b[A\n",
      " 71% 7549/10570 [00:14<00:06, 495.79it/s]\u001b[A\n",
      " 72% 7602/10570 [00:14<00:05, 504.78it/s]\u001b[A\n",
      " 72% 7653/10570 [00:14<00:05, 501.80it/s]\u001b[A\n",
      " 73% 7705/10570 [00:15<00:05, 505.42it/s]\u001b[A\n",
      " 73% 7757/10570 [00:15<00:05, 508.44it/s]\u001b[A\n",
      " 74% 7809/10570 [00:15<00:05, 509.61it/s]\u001b[A\n",
      " 74% 7861/10570 [00:15<00:05, 510.93it/s]\u001b[A\n",
      " 75% 7914/10570 [00:15<00:05, 514.00it/s]\u001b[A\n",
      " 75% 7967/10570 [00:15<00:05, 517.36it/s]\u001b[A\n",
      " 76% 8019/10570 [00:15<00:04, 514.77it/s]\u001b[A\n",
      " 76% 8071/10570 [00:15<00:04, 514.94it/s]\u001b[A\n",
      " 77% 8125/10570 [00:15<00:04, 520.02it/s]\u001b[A\n",
      " 77% 8178/10570 [00:15<00:04, 513.63it/s]\u001b[A\n",
      " 78% 8230/10570 [00:16<00:04, 511.92it/s]\u001b[A\n",
      " 78% 8282/10570 [00:16<00:04, 505.42it/s]\u001b[A\n",
      " 79% 8333/10570 [00:16<00:04, 504.87it/s]\u001b[A\n",
      " 79% 8386/10570 [00:16<00:04, 511.11it/s]\u001b[A\n",
      " 80% 8438/10570 [00:16<00:04, 512.11it/s]\u001b[A\n",
      " 80% 8491/10570 [00:16<00:04, 513.90it/s]\u001b[A\n",
      " 81% 8543/10570 [00:16<00:03, 515.51it/s]\u001b[A\n",
      " 81% 8596/10570 [00:16<00:03, 517.30it/s]\u001b[A\n",
      " 82% 8648/10570 [00:16<00:03, 517.40it/s]\u001b[A\n",
      " 82% 8701/10570 [00:16<00:03, 520.56it/s]\u001b[A\n",
      " 83% 8754/10570 [00:17<00:03, 516.50it/s]\u001b[A\n",
      " 83% 8806/10570 [00:17<00:03, 514.78it/s]\u001b[A\n",
      " 84% 8859/10570 [00:17<00:03, 516.35it/s]\u001b[A\n",
      " 84% 8911/10570 [00:17<00:03, 515.34it/s]\u001b[A\n",
      " 85% 8963/10570 [00:17<00:03, 515.32it/s]\u001b[A\n",
      " 85% 9016/10570 [00:17<00:02, 519.14it/s]\u001b[A\n",
      " 86% 9068/10570 [00:17<00:02, 518.26it/s]\u001b[A\n",
      " 86% 9120/10570 [00:17<00:02, 517.48it/s]\u001b[A\n",
      " 87% 9172/10570 [00:17<00:02, 517.52it/s]\u001b[A\n",
      " 87% 9224/10570 [00:17<00:02, 517.02it/s]\u001b[A\n",
      " 88% 9276/10570 [00:18<00:02, 517.54it/s]\u001b[A\n",
      " 88% 9328/10570 [00:18<00:02, 517.35it/s]\u001b[A\n",
      " 89% 9380/10570 [00:18<00:02, 517.77it/s]\u001b[A\n",
      " 89% 9433/10570 [00:18<00:02, 520.47it/s]\u001b[A\n",
      " 90% 9486/10570 [00:18<00:02, 520.77it/s]\u001b[A\n",
      " 90% 9539/10570 [00:18<00:01, 522.05it/s]\u001b[A\n",
      " 91% 9592/10570 [00:18<00:01, 521.17it/s]\u001b[A\n",
      " 91% 9645/10570 [00:18<00:01, 522.24it/s]\u001b[A\n",
      " 92% 9698/10570 [00:18<00:01, 524.11it/s]\u001b[A\n",
      " 92% 9751/10570 [00:18<00:01, 525.19it/s]\u001b[A\n",
      " 93% 9804/10570 [00:19<00:01, 523.37it/s]\u001b[A\n",
      " 93% 9857/10570 [00:19<00:01, 519.86it/s]\u001b[A\n",
      " 94% 9909/10570 [00:19<00:01, 519.54it/s]\u001b[A\n",
      " 94% 9962/10570 [00:19<00:01, 521.80it/s]\u001b[A\n",
      " 95% 10015/10570 [00:19<00:01, 521.01it/s]\u001b[A\n",
      " 95% 10068/10570 [00:19<00:00, 517.12it/s]\u001b[A\n",
      " 96% 10121/10570 [00:19<00:00, 519.47it/s]\u001b[A\n",
      " 96% 10174/10570 [00:19<00:00, 521.77it/s]\u001b[A\n",
      " 97% 10227/10570 [00:19<00:00, 521.18it/s]\u001b[A\n",
      " 97% 10280/10570 [00:19<00:00, 519.34it/s]\u001b[A\n",
      " 98% 10332/10570 [00:20<00:00, 517.77it/s]\u001b[A\n",
      " 98% 10384/10570 [00:20<00:00, 517.10it/s]\u001b[A\n",
      " 99% 10436/10570 [00:20<00:00, 514.72it/s]\u001b[A\n",
      " 99% 10488/10570 [00:20<00:00, 514.56it/s]\u001b[A\n",
      "100% 10570/10570 [00:20<00:00, 514.39it/s]\n",
      "100% 1329/1329 [01:06<00:00, 20.02it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 76.3670766319773, 'eval_f1': 84.48631134638232, 'epoch': 3.0}\n",
      " 96% 106/110 [00:02<00:00, 46.15it/s]\n",
      "  0% 0/870 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 52/870 [00:00<00:01, 512.45it/s]\u001b[A\n",
      " 12% 104/870 [00:00<00:01, 513.75it/s]\u001b[A\n",
      " 18% 156/870 [00:00<00:01, 515.04it/s]\u001b[A\n",
      " 24% 209/870 [00:00<00:01, 520.50it/s]\u001b[A\n",
      " 30% 262/870 [00:00<00:01, 515.67it/s]\u001b[A\n",
      " 36% 315/870 [00:00<00:01, 517.76it/s]\u001b[A\n",
      " 42% 367/870 [00:00<00:00, 515.27it/s]\u001b[A\n",
      " 48% 419/870 [00:00<00:00, 498.29it/s]\u001b[A\n",
      " 54% 470/870 [00:00<00:00, 498.58it/s]\u001b[A\n",
      " 60% 521/870 [00:01<00:00, 501.97it/s]\u001b[A\n",
      " 66% 572/870 [00:01<00:00, 501.89it/s]\u001b[A\n",
      " 72% 623/870 [00:01<00:00, 500.74it/s]\u001b[A\n",
      " 77% 674/870 [00:01<00:00, 501.45it/s]\u001b[A\n",
      " 83% 726/870 [00:01<00:00, 504.49it/s]\u001b[A\n",
      " 89% 777/870 [00:01<00:00, 505.21it/s]\u001b[A\n",
      "100% 870/870 [00:01<00:00, 506.70it/s]\n",
      "100% 110/110 [00:05<00:00, 19.93it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 22.64367816091954, 'eval_f1': 28.375732831376975, 'epoch': 3.0}\n",
      " 96% 55/57 [00:01<00:00, 45.98it/s]\n",
      "  0% 0/452 [00:00<?, ?it/s]\u001b[A\n",
      " 12% 52/452 [00:00<00:00, 514.36it/s]\u001b[A\n",
      " 23% 104/452 [00:00<00:00, 507.67it/s]\u001b[A\n",
      " 35% 156/452 [00:00<00:00, 509.05it/s]\u001b[A\n",
      " 46% 208/452 [00:00<00:00, 512.80it/s]\u001b[A\n",
      " 58% 260/452 [00:00<00:00, 504.90it/s]\u001b[A\n",
      " 69% 311/452 [00:00<00:00, 501.42it/s]\u001b[A\n",
      " 80% 362/452 [00:00<00:00, 500.86it/s]\u001b[A\n",
      "100% 452/452 [00:00<00:00, 504.21it/s]\n",
      "100% 57/57 [00:02<00:00, 19.78it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 24.336283185840706, 'eval_f1': 29.435952170847678, 'epoch': 3.0}\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m./trained_model_final3/\u001b[0m at: \u001b[34mhttps://wandb.ai/billiam1100-/huggingface/runs/siuxr8zi\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241203_145739-siuxr8zi/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model_final3/ --perc_squad 1 --perc_adversarial_squad 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EMLpVsSXTAP0",
    "outputId": "04641f8f-a7f6-4ac5-d51d-ff56e39ec532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-27 03:10:54.313383: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 03:10:54.330144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-27 03:10:54.350944: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-27 03:10:54.357407: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 03:10:54.372728: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 03:10:55.624587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "README.md: 100% 7.62k/7.62k [00:00<00:00, 47.3MB/s]\n",
      "train-00000-of-00001.parquet: 100% 14.5M/14.5M [00:00<00:00, 99.3MB/s]\n",
      "validation-00000-of-00001.parquet: 100% 1.82M/1.82M [00:00<00:00, 178MB/s]\n",
      "Generating train split: 100% 87599/87599 [00:00<00:00, 414110.25 examples/s]\n",
      "Generating validation split: 100% 10570/10570 [00:00<00:00, 476563.97 examples/s]\n",
      "config.json: 100% 665/665 [00:00<00:00, 5.92MB/s]\n",
      "pytorch_model.bin: 100% 54.2M/54.2M [00:00<00:00, 176MB/s]\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 382kB/s]\n",
      "vocab.txt: 100% 232k/232k [00:00<00:00, 6.08MB/s]\n",
      "tokenizer.json: 100% 466k/466k [00:00<00:00, 22.9MB/s]\n",
      "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
      "README.md: 100% 9.19k/9.19k [00:00<00:00, 45.2MB/s]\n",
      "hotpot_qa.py: 100% 6.42k/6.42k [00:00<00:00, 48.1MB/s]\n",
      "model.safetensors: 100% 54.2M/54.2M [00:00<00:00, 168MB/s]\n",
      "Downloading data: 100% 566M/566M [00:22<00:00, 24.8MB/s]\n",
      "Downloading data: 100% 47.5M/47.5M [00:04<00:00, 10.4MB/s]\n",
      "Downloading data: 100% 46.2M/46.2M [00:03<00:00, 12.8MB/s]\n",
      "Generating train split: 100% 90447/90447 [00:32<00:00, 2792.71 examples/s]\n",
      "Generating validation split: 100% 7405/7405 [00:02<00:00, 3213.74 examples/s]\n",
      "Generating test split: 100% 7405/7405 [00:02<00:00, 3553.20 examples/s]\n",
      "Map: 100% 90447/90447 [00:20<00:00, 4482.18 examples/s]\n",
      "Casting the dataset: 100% 90447/90447 [00:00<00:00, 95107.81 examples/s] \n",
      "Filter: 100% 90447/90447 [00:03<00:00, 23927.98 examples/s]\n",
      "Map (num_proc=2): 100% 175395/175395 [07:14<00:00, 403.58 examples/s]\n",
      "Map (num_proc=2): 100% 10570/10570 [00:05<00:00, 1813.57 examples/s]\n",
      "Downloading builder script: 100% 4.53k/4.53k [00:00<00:00, 19.6MB/s]\n",
      "Downloading extra modules: 100% 3.32k/3.32k [00:00<00:00, 19.4MB/s]\n",
      "\n",
      "Beginning Pipeline!\n",
      "\n",
      "/content/dsc388/Final Project/Repo/helpers.py:277: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "\n",
      "Beginning Evaluation!\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/dsc388/Final Project/Repo/wandb/run-20241127_032012-bnkm7803\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./trained_model/\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface/runs/bnkm7803\u001b[0m\n",
      "  1% 56/9177 [00:35<1:31:23,  1.66it/s]"
     ]
    }
   ],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model_final/ --perc_squad 1 --perc_hotpotqa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6300043,
     "status": "ok",
     "timestamp": 1733062476747,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "wbEDc8ShLzlZ",
    "outputId": "7582ff07-4b56-4082-e5ee-3a18fae7798f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-01 12:29:44.801690: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-01 12:29:44.817705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 12:29:44.838767: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 12:29:44.845092: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-01 12:29:44.860279: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-01 12:29:46.117601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "README.md: 100% 7.62k/7.62k [00:00<00:00, 40.8MB/s]\n",
      "train-00000-of-00001.parquet: 100% 14.5M/14.5M [00:00<00:00, 105MB/s] \n",
      "validation-00000-of-00001.parquet: 100% 1.82M/1.82M [00:00<00:00, 204MB/s]\n",
      "Generating train split: 100% 87599/87599 [00:00<00:00, 394651.33 examples/s]\n",
      "Generating validation split: 100% 10570/10570 [00:00<00:00, 439671.08 examples/s]\n",
      "config.json: 100% 665/665 [00:00<00:00, 4.74MB/s]\n",
      "pytorch_model.bin: 100% 54.2M/54.2M [00:00<00:00, 137MB/s]\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 454kB/s]\n",
      "vocab.txt: 100% 232k/232k [00:00<00:00, 5.93MB/s]\n",
      "tokenizer.json: 100% 466k/466k [00:00<00:00, 11.9MB/s]\n",
      "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
      "README.md: 100% 8.54k/8.54k [00:00<00:00, 35.1MB/s]\n",
      "squad_adversarial.py: 100% 5.74k/5.74k [00:00<00:00, 35.5MB/s]\n",
      "Downloading data: 4.07MB [00:00, 42.3MB/s]\n",
      "Downloading data: 1.92MB [00:00, 20.0MB/s]\n",
      "Generating validation split: 100% 3560/3560 [00:00<00:00, 10782.86 examples/s]\n",
      "README.md: 100% 9.19k/9.19k [00:00<00:00, 41.3MB/s]\n",
      "hotpot_qa.py: 100% 6.42k/6.42k [00:00<00:00, 35.5MB/s]\n",
      "Downloading data: 100% 566M/566M [00:30<00:00, 18.4MB/s]\n",
      "Downloading data: 100% 47.5M/47.5M [00:01<00:00, 31.0MB/s]\n",
      "Downloading data: 100% 46.2M/46.2M [00:01<00:00, 40.0MB/s]\n",
      "Generating train split: 100% 90447/90447 [00:32<00:00, 2816.71 examples/s]\n",
      "Generating validation split: 100% 7405/7405 [00:02<00:00, 2938.90 examples/s]\n",
      "Generating test split: 100% 7405/7405 [00:02<00:00, 2976.86 examples/s]\n",
      "Map: 100% 90447/90447 [00:20<00:00, 4456.98 examples/s]\n",
      "Casting the dataset: 100% 90447/90447 [00:00<00:00, 90926.62 examples/s] \n",
      "Filter: 100% 90447/90447 [00:03<00:00, 24547.38 examples/s]\n",
      "Map (num_proc=2): 100% 178955/178955 [07:17<00:00, 409.27 examples/s]\n",
      "Map (num_proc=2): 100% 10570/10570 [00:06<00:00, 1694.58 examples/s]\n",
      "Downloading builder script: 100% 4.53k/4.53k [00:00<00:00, 16.6MB/s]\n",
      "Downloading extra modules: 100% 3.32k/3.32k [00:00<00:00, 16.4MB/s]\n",
      "\n",
      "Beginning Pipeline!\n",
      "\n",
      "/content/dsc388/Final Project/Repo/helpers.py:277: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "\n",
      "Beginning Evaluation!\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/dsc388/Final Project/Repo/wandb/run-20241201_123917-q3ts92l0\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./trained_model_final_1/\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface/runs/q3ts92l0\u001b[0m\n",
      "{'loss': 2.4243, 'grad_norm': 5.693788051605225, 'learning_rate': 4.730050750458914e-05, 'epoch': 0.16}\n",
      "{'loss': 1.3836, 'grad_norm': 7.142526149749756, 'learning_rate': 4.4601015009178276e-05, 'epoch': 0.32}\n",
      "{'loss': 1.2373, 'grad_norm': 5.7111310958862305, 'learning_rate': 4.190152251376741e-05, 'epoch': 0.49}\n",
      "{'loss': 1.1622, 'grad_norm': 6.674749374389648, 'learning_rate': 3.920203001835655e-05, 'epoch': 0.65}\n",
      "{'loss': 1.0942, 'grad_norm': 4.959690570831299, 'learning_rate': 3.650253752294569e-05, 'epoch': 0.81}\n",
      "{'loss': 1.0739, 'grad_norm': 5.948699474334717, 'learning_rate': 3.380304502753482e-05, 'epoch': 0.97}\n",
      "{'loss': 0.9877, 'grad_norm': 6.16517448425293, 'learning_rate': 3.110355253212397e-05, 'epoch': 1.13}\n",
      "{'loss': 0.9623, 'grad_norm': 5.564210414886475, 'learning_rate': 2.8404060036713097e-05, 'epoch': 1.3}\n",
      "{'loss': 0.9465, 'grad_norm': 5.610191822052002, 'learning_rate': 2.5704567541302237e-05, 'epoch': 1.46}\n",
      "{'loss': 0.9351, 'grad_norm': 5.301764965057373, 'learning_rate': 2.3005075045891374e-05, 'epoch': 1.62}\n",
      "{'loss': 0.9217, 'grad_norm': 4.948980331420898, 'learning_rate': 2.030558255048051e-05, 'epoch': 1.78}\n",
      "{'loss': 0.9183, 'grad_norm': 5.99037504196167, 'learning_rate': 1.760609005506965e-05, 'epoch': 1.94}\n",
      "{'loss': 0.8685, 'grad_norm': 6.5187458992004395, 'learning_rate': 1.4906597559658786e-05, 'epoch': 2.11}\n",
      "{'loss': 0.8355, 'grad_norm': 5.606604099273682, 'learning_rate': 1.220710506424792e-05, 'epoch': 2.27}\n",
      "{'loss': 0.8442, 'grad_norm': 5.0114288330078125, 'learning_rate': 9.50761256883706e-06, 'epoch': 2.43}\n",
      "{'loss': 0.8396, 'grad_norm': 5.458653926849365, 'learning_rate': 6.808120073426197e-06, 'epoch': 2.59}\n",
      "{'loss': 0.8424, 'grad_norm': 5.283337116241455, 'learning_rate': 4.108627578015333e-06, 'epoch': 2.75}\n",
      "{'loss': 0.8323, 'grad_norm': 5.4308390617370605, 'learning_rate': 1.4091350826044704e-06, 'epoch': 2.92}\n",
      "{'train_runtime': 5647.3002, 'train_samples_per_second': 209.88, 'train_steps_per_second': 1.64, 'train_loss': 1.0551724200654964, 'epoch': 3.0}\n",
      "100% 9261/9261 [1:33:52<00:00,  1.64it/s]\n",
      "100% 1329/1329 [00:41<00:00, 45.37it/s]\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\n",
      "  0% 45/10570 [00:00<00:23, 444.10it/s]\u001b[A\n",
      "  1% 98/10570 [00:00<00:21, 491.10it/s]\u001b[A\n",
      "  1% 150/10570 [00:00<00:20, 502.63it/s]\u001b[A\n",
      "  2% 202/10570 [00:00<00:20, 507.31it/s]\u001b[A\n",
      "  2% 253/10570 [00:00<00:20, 496.13it/s]\u001b[A\n",
      "  3% 303/10570 [00:00<00:20, 489.37it/s]\u001b[A\n",
      "  3% 357/10570 [00:00<00:20, 502.69it/s]\u001b[A\n",
      "  4% 409/10570 [00:00<00:20, 506.10it/s]\u001b[A\n",
      "  4% 461/10570 [00:00<00:19, 508.71it/s]\u001b[A\n",
      "  5% 514/10570 [00:01<00:19, 513.17it/s]\u001b[A\n",
      "  5% 566/10570 [00:01<00:19, 509.82it/s]\u001b[A\n",
      "  6% 617/10570 [00:01<00:19, 500.67it/s]\u001b[A\n",
      "  6% 670/10570 [00:01<00:19, 507.19it/s]\u001b[A\n",
      "  7% 722/10570 [00:01<00:19, 508.86it/s]\u001b[A\n",
      "  7% 773/10570 [00:01<00:19, 508.53it/s]\u001b[A\n",
      "  8% 824/10570 [00:01<00:19, 500.15it/s]\u001b[A\n",
      "  8% 875/10570 [00:01<00:19, 502.11it/s]\u001b[A\n",
      "  9% 926/10570 [00:01<00:19, 500.15it/s]\u001b[A\n",
      "  9% 977/10570 [00:01<00:19, 499.13it/s]\u001b[A\n",
      " 10% 1027/10570 [00:02<00:19, 498.68it/s]\u001b[A\n",
      " 10% 1077/10570 [00:02<00:19, 498.51it/s]\u001b[A\n",
      " 11% 1127/10570 [00:02<00:19, 489.61it/s]\u001b[A\n",
      " 11% 1179/10570 [00:02<00:18, 498.41it/s]\u001b[A\n",
      " 12% 1230/10570 [00:02<00:18, 500.05it/s]\u001b[A\n",
      " 12% 1281/10570 [00:02<00:18, 499.10it/s]\u001b[A\n",
      " 13% 1333/10570 [00:02<00:18, 502.96it/s]\u001b[A\n",
      " 13% 1384/10570 [00:02<00:18, 502.33it/s]\u001b[A\n",
      " 14% 1435/10570 [00:02<00:18, 502.60it/s]\u001b[A\n",
      " 14% 1486/10570 [00:02<00:17, 504.74it/s]\u001b[A\n",
      " 15% 1537/10570 [00:03<00:17, 504.12it/s]\u001b[A\n",
      " 15% 1589/10570 [00:03<00:17, 507.68it/s]\u001b[A\n",
      " 16% 1640/10570 [00:03<00:17, 504.87it/s]\u001b[A\n",
      " 16% 1691/10570 [00:03<00:17, 506.27it/s]\u001b[A\n",
      " 16% 1742/10570 [00:03<00:17, 506.78it/s]\u001b[A\n",
      " 17% 1793/10570 [00:03<00:17, 507.55it/s]\u001b[A\n",
      " 17% 1844/10570 [00:03<00:17, 506.31it/s]\u001b[A\n",
      " 18% 1897/10570 [00:03<00:16, 510.48it/s]\u001b[A\n",
      " 18% 1949/10570 [00:03<00:16, 510.71it/s]\u001b[A\n",
      " 19% 2001/10570 [00:03<00:16, 512.14it/s]\u001b[A\n",
      " 19% 2053/10570 [00:04<00:16, 513.22it/s]\u001b[A\n",
      " 20% 2105/10570 [00:04<00:16, 514.91it/s]\u001b[A\n",
      " 20% 2157/10570 [00:04<00:16, 506.87it/s]\u001b[A\n",
      " 21% 2208/10570 [00:04<00:16, 507.21it/s]\u001b[A\n",
      " 21% 2260/10570 [00:04<00:16, 508.27it/s]\u001b[A\n",
      " 22% 2311/10570 [00:04<00:16, 507.76it/s]\u001b[A\n",
      " 22% 2363/10570 [00:04<00:16, 509.37it/s]\u001b[A\n",
      " 23% 2414/10570 [00:04<00:16, 504.87it/s]\u001b[A\n",
      " 23% 2465/10570 [00:04<00:16, 502.34it/s]\u001b[A\n",
      " 24% 2516/10570 [00:04<00:16, 499.56it/s]\u001b[A\n",
      " 24% 2566/10570 [00:05<00:16, 494.52it/s]\u001b[A\n",
      " 25% 2617/10570 [00:05<00:16, 496.67it/s]\u001b[A\n",
      " 25% 2669/10570 [00:05<00:15, 502.76it/s]\u001b[A\n",
      " 26% 2720/10570 [00:05<00:15, 500.66it/s]\u001b[A\n",
      " 26% 2773/10570 [00:05<00:15, 508.05it/s]\u001b[A\n",
      " 27% 2825/10570 [00:05<00:15, 510.18it/s]\u001b[A\n",
      " 27% 2877/10570 [00:05<00:15, 508.63it/s]\u001b[A\n",
      " 28% 2928/10570 [00:05<00:15, 504.65it/s]\u001b[A\n",
      " 28% 2979/10570 [00:05<00:15, 504.49it/s]\u001b[A\n",
      " 29% 3030/10570 [00:06<00:14, 504.85it/s]\u001b[A\n",
      " 29% 3081/10570 [00:06<00:14, 503.64it/s]\u001b[A\n",
      " 30% 3132/10570 [00:06<00:14, 503.38it/s]\u001b[A\n",
      " 30% 3183/10570 [00:06<00:14, 499.75it/s]\u001b[A\n",
      " 31% 3233/10570 [00:06<00:14, 499.10it/s]\u001b[A\n",
      " 31% 3283/10570 [00:06<00:14, 496.08it/s]\u001b[A\n",
      " 32% 3334/10570 [00:06<00:14, 499.32it/s]\u001b[A\n",
      " 32% 3384/10570 [00:06<00:14, 499.42it/s]\u001b[A\n",
      " 32% 3434/10570 [00:06<00:14, 497.32it/s]\u001b[A\n",
      " 33% 3484/10570 [00:06<00:14, 496.22it/s]\u001b[A\n",
      " 33% 3535/10570 [00:07<00:14, 499.65it/s]\u001b[A\n",
      " 34% 3585/10570 [00:07<00:14, 493.77it/s]\u001b[A\n",
      " 34% 3635/10570 [00:07<00:14, 494.40it/s]\u001b[A\n",
      " 35% 3685/10570 [00:07<00:14, 490.16it/s]\u001b[A\n",
      " 35% 3735/10570 [00:07<00:13, 489.93it/s]\u001b[A\n",
      " 36% 3786/10570 [00:07<00:13, 494.68it/s]\u001b[A\n",
      " 36% 3836/10570 [00:07<00:13, 495.54it/s]\u001b[A\n",
      " 37% 3886/10570 [00:07<00:13, 496.80it/s]\u001b[A\n",
      " 37% 3936/10570 [00:07<00:13, 496.07it/s]\u001b[A\n",
      " 38% 3987/10570 [00:07<00:13, 498.81it/s]\u001b[A\n",
      " 38% 4037/10570 [00:08<00:13, 497.67it/s]\u001b[A\n",
      " 39% 4087/10570 [00:08<00:13, 497.61it/s]\u001b[A\n",
      " 39% 4137/10570 [00:08<00:13, 485.41it/s]\u001b[A\n",
      " 40% 4186/10570 [00:08<00:14, 428.51it/s]\u001b[A\n",
      " 40% 4231/10570 [00:08<00:15, 419.95it/s]\u001b[A\n",
      " 40% 4274/10570 [00:08<00:15, 398.85it/s]\u001b[A\n",
      " 41% 4315/10570 [00:08<00:16, 376.67it/s]\u001b[A\n",
      " 41% 4365/10570 [00:08<00:15, 407.71it/s]\u001b[A\n",
      " 42% 4414/10570 [00:08<00:14, 429.78it/s]\u001b[A\n",
      " 42% 4465/10570 [00:09<00:13, 451.71it/s]\u001b[A\n",
      " 43% 4513/10570 [00:09<00:13, 459.27it/s]\u001b[A\n",
      " 43% 4560/10570 [00:09<00:12, 462.33it/s]\u001b[A\n",
      " 44% 4608/10570 [00:09<00:12, 465.52it/s]\u001b[A\n",
      " 44% 4656/10570 [00:09<00:12, 467.82it/s]\u001b[A\n",
      " 45% 4706/10570 [00:09<00:12, 474.68it/s]\u001b[A\n",
      " 45% 4756/10570 [00:09<00:12, 479.91it/s]\u001b[A\n",
      " 45% 4805/10570 [00:09<00:12, 480.30it/s]\u001b[A\n",
      " 46% 4854/10570 [00:09<00:12, 472.54it/s]\u001b[A\n",
      " 46% 4906/10570 [00:09<00:11, 484.38it/s]\u001b[A\n",
      " 47% 4956/10570 [00:10<00:11, 488.54it/s]\u001b[A\n",
      " 47% 5005/10570 [00:10<00:11, 484.60it/s]\u001b[A\n",
      " 48% 5055/10570 [00:10<00:11, 487.32it/s]\u001b[A\n",
      " 48% 5104/10570 [00:10<00:11, 486.82it/s]\u001b[A\n",
      " 49% 5154/10570 [00:10<00:11, 489.45it/s]\u001b[A\n",
      " 49% 5204/10570 [00:10<00:10, 490.72it/s]\u001b[A\n",
      " 50% 5254/10570 [00:10<00:10, 490.55it/s]\u001b[A\n",
      " 50% 5306/10570 [00:10<00:10, 497.38it/s]\u001b[A\n",
      " 51% 5356/10570 [00:10<00:10, 497.76it/s]\u001b[A\n",
      " 51% 5407/10570 [00:10<00:10, 498.97it/s]\u001b[A\n",
      " 52% 5457/10570 [00:11<00:10, 492.48it/s]\u001b[A\n",
      " 52% 5507/10570 [00:11<00:10, 487.51it/s]\u001b[A\n",
      " 53% 5556/10570 [00:11<00:10, 485.40it/s]\u001b[A\n",
      " 53% 5605/10570 [00:11<00:10, 485.40it/s]\u001b[A\n",
      " 53% 5654/10570 [00:11<00:10, 481.58it/s]\u001b[A\n",
      " 54% 5704/10570 [00:11<00:10, 486.37it/s]\u001b[A\n",
      " 54% 5754/10570 [00:11<00:09, 489.90it/s]\u001b[A\n",
      " 55% 5804/10570 [00:11<00:09, 488.68it/s]\u001b[A\n",
      " 55% 5854/10570 [00:11<00:09, 490.75it/s]\u001b[A\n",
      " 56% 5904/10570 [00:12<00:09, 491.18it/s]\u001b[A\n",
      " 56% 5954/10570 [00:12<00:09, 480.88it/s]\u001b[A\n",
      " 57% 6004/10570 [00:12<00:09, 483.69it/s]\u001b[A\n",
      " 57% 6053/10570 [00:12<00:09, 484.75it/s]\u001b[A\n",
      " 58% 6102/10570 [00:12<00:09, 482.42it/s]\u001b[A\n",
      " 58% 6153/10570 [00:12<00:09, 489.03it/s]\u001b[A\n",
      " 59% 6203/10570 [00:12<00:08, 490.97it/s]\u001b[A\n",
      " 59% 6253/10570 [00:12<00:08, 489.77it/s]\u001b[A\n",
      " 60% 6304/10570 [00:12<00:08, 494.22it/s]\u001b[A\n",
      " 60% 6354/10570 [00:12<00:08, 491.86it/s]\u001b[A\n",
      " 61% 6404/10570 [00:13<00:08, 475.44it/s]\u001b[A\n",
      " 61% 6455/10570 [00:13<00:08, 483.72it/s]\u001b[A\n",
      " 62% 6504/10570 [00:13<00:08, 484.37it/s]\u001b[A\n",
      " 62% 6554/10570 [00:13<00:08, 488.10it/s]\u001b[A\n",
      " 62% 6603/10570 [00:13<00:08, 485.47it/s]\u001b[A\n",
      " 63% 6653/10570 [00:13<00:08, 489.29it/s]\u001b[A\n",
      " 63% 6702/10570 [00:13<00:07, 489.05it/s]\u001b[A\n",
      " 64% 6752/10570 [00:13<00:07, 490.77it/s]\u001b[A\n",
      " 64% 6802/10570 [00:13<00:07, 490.13it/s]\u001b[A\n",
      " 65% 6852/10570 [00:13<00:07, 485.70it/s]\u001b[A\n",
      " 65% 6901/10570 [00:14<00:07, 486.42it/s]\u001b[A\n",
      " 66% 6950/10570 [00:14<00:07, 486.10it/s]\u001b[A\n",
      " 66% 7000/10570 [00:14<00:07, 488.43it/s]\u001b[A\n",
      " 67% 7049/10570 [00:14<00:07, 486.25it/s]\u001b[A\n",
      " 67% 7098/10570 [00:14<00:07, 487.00it/s]\u001b[A\n",
      " 68% 7149/10570 [00:14<00:06, 492.13it/s]\u001b[A\n",
      " 68% 7199/10570 [00:14<00:06, 493.16it/s]\u001b[A\n",
      " 69% 7249/10570 [00:14<00:06, 494.15it/s]\u001b[A\n",
      " 69% 7299/10570 [00:14<00:06, 492.74it/s]\u001b[A\n",
      " 70% 7349/10570 [00:14<00:06, 482.58it/s]\u001b[A\n",
      " 70% 7399/10570 [00:15<00:06, 486.82it/s]\u001b[A\n",
      " 70% 7450/10570 [00:15<00:06, 491.07it/s]\u001b[A\n",
      " 71% 7500/10570 [00:15<00:06, 488.66it/s]\u001b[A\n",
      " 71% 7549/10570 [00:15<00:06, 465.26it/s]\u001b[A\n",
      " 72% 7597/10570 [00:15<00:06, 467.37it/s]\u001b[A\n",
      " 72% 7647/10570 [00:15<00:06, 475.24it/s]\u001b[A\n",
      " 73% 7698/10570 [00:15<00:05, 482.87it/s]\u001b[A\n",
      " 73% 7748/10570 [00:15<00:05, 486.30it/s]\u001b[A\n",
      " 74% 7798/10570 [00:15<00:05, 488.37it/s]\u001b[A\n",
      " 74% 7848/10570 [00:16<00:05, 490.57it/s]\u001b[A\n",
      " 75% 7899/10570 [00:16<00:05, 494.65it/s]\u001b[A\n",
      " 75% 7950/10570 [00:16<00:05, 497.72it/s]\u001b[A\n",
      " 76% 8000/10570 [00:16<00:05, 492.21it/s]\u001b[A\n",
      " 76% 8050/10570 [00:16<00:05, 487.62it/s]\u001b[A\n",
      " 77% 8102/10570 [00:16<00:04, 495.01it/s]\u001b[A\n",
      " 77% 8152/10570 [00:16<00:04, 494.77it/s]\u001b[A\n",
      " 78% 8202/10570 [00:16<00:04, 492.00it/s]\u001b[A\n",
      " 78% 8252/10570 [00:16<00:04, 490.05it/s]\u001b[A\n",
      " 79% 8302/10570 [00:16<00:04, 486.50it/s]\u001b[A\n",
      " 79% 8352/10570 [00:17<00:04, 489.50it/s]\u001b[A\n",
      " 79% 8403/10570 [00:17<00:04, 492.64it/s]\u001b[A\n",
      " 80% 8455/10570 [00:17<00:04, 498.45it/s]\u001b[A\n",
      " 80% 8505/10570 [00:17<00:04, 485.72it/s]\u001b[A\n",
      " 81% 8554/10570 [00:17<00:04, 481.34it/s]\u001b[A\n",
      " 81% 8604/10570 [00:17<00:04, 485.51it/s]\u001b[A\n",
      " 82% 8653/10570 [00:17<00:03, 485.96it/s]\u001b[A\n",
      " 82% 8704/10570 [00:17<00:03, 490.96it/s]\u001b[A\n",
      " 83% 8754/10570 [00:17<00:03, 488.66it/s]\u001b[A\n",
      " 83% 8803/10570 [00:17<00:03, 488.32it/s]\u001b[A\n",
      " 84% 8853/10570 [00:18<00:03, 490.36it/s]\u001b[A\n",
      " 84% 8903/10570 [00:18<00:03, 491.91it/s]\u001b[A\n",
      " 85% 8953/10570 [00:18<00:03, 492.81it/s]\u001b[A\n",
      " 85% 9003/10570 [00:18<00:03, 492.19it/s]\u001b[A\n",
      " 86% 9053/10570 [00:18<00:03, 491.59it/s]\u001b[A\n",
      " 86% 9103/10570 [00:18<00:02, 491.60it/s]\u001b[A\n",
      " 87% 9153/10570 [00:18<00:02, 492.04it/s]\u001b[A\n",
      " 87% 9204/10570 [00:18<00:02, 494.60it/s]\u001b[A\n",
      " 88% 9255/10570 [00:18<00:02, 496.33it/s]\u001b[A\n",
      " 88% 9306/10570 [00:18<00:02, 497.55it/s]\u001b[A\n",
      " 89% 9356/10570 [00:19<00:02, 497.41it/s]\u001b[A\n",
      " 89% 9406/10570 [00:19<00:02, 497.17it/s]\u001b[A\n",
      " 89% 9456/10570 [00:19<00:02, 495.98it/s]\u001b[A\n",
      " 90% 9506/10570 [00:19<00:02, 483.42it/s]\u001b[A\n",
      " 90% 9558/10570 [00:19<00:02, 492.20it/s]\u001b[A\n",
      " 91% 9609/10570 [00:19<00:01, 496.04it/s]\u001b[A\n",
      " 91% 9660/10570 [00:19<00:01, 499.18it/s]\u001b[A\n",
      " 92% 9711/10570 [00:19<00:01, 501.72it/s]\u001b[A\n",
      " 92% 9763/10570 [00:19<00:01, 504.46it/s]\u001b[A\n",
      " 93% 9814/10570 [00:19<00:01, 502.35it/s]\u001b[A\n",
      " 93% 9865/10570 [00:20<00:01, 499.39it/s]\u001b[A\n",
      " 94% 9916/10570 [00:20<00:01, 500.08it/s]\u001b[A\n",
      " 94% 9967/10570 [00:20<00:01, 500.11it/s]\u001b[A\n",
      " 95% 10018/10570 [00:20<00:01, 496.45it/s]\u001b[A\n",
      " 95% 10069/10570 [00:20<00:01, 498.92it/s]\u001b[A\n",
      " 96% 10120/10570 [00:20<00:00, 499.95it/s]\u001b[A\n",
      " 96% 10171/10570 [00:20<00:00, 499.88it/s]\u001b[A\n",
      " 97% 10221/10570 [00:20<00:00, 499.75it/s]\u001b[A\n",
      " 97% 10271/10570 [00:20<00:00, 498.52it/s]\u001b[A\n",
      " 98% 10321/10570 [00:21<00:00, 497.79it/s]\u001b[A\n",
      " 98% 10371/10570 [00:21<00:00, 498.36it/s]\u001b[A\n",
      " 99% 10421/10570 [00:21<00:00, 496.51it/s]\u001b[A\n",
      " 99% 10471/10570 [00:21<00:00, 489.65it/s]\u001b[A\n",
      "100% 10570/10570 [00:21<00:00, 491.13it/s]\n",
      "100% 1329/1329 [01:08<00:00, 19.41it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 77.22800378429517, 'eval_f1': 85.02821888805224, 'epoch': 3.0}\n",
      "Filter: 100% 10570/10570 [00:00<00:00, 30011.11 examples/s]\n",
      "Map (num_proc=2): 100% 870/870 [00:00<00:00, 1279.00 examples/s]\n",
      " 95% 105/110 [00:02<00:00, 45.44it/s]\n",
      "  0% 0/870 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 50/870 [00:00<00:01, 498.63it/s]\u001b[A\n",
      " 12% 101/870 [00:00<00:01, 499.07it/s]\u001b[A\n",
      " 17% 151/870 [00:00<00:01, 498.94it/s]\u001b[A\n",
      " 23% 202/870 [00:00<00:01, 502.61it/s]\u001b[A\n",
      " 29% 253/870 [00:00<00:01, 500.57it/s]\u001b[A\n",
      " 35% 304/870 [00:00<00:01, 501.42it/s]\u001b[A\n",
      " 41% 355/870 [00:00<00:01, 500.18it/s]\u001b[A\n",
      " 47% 406/870 [00:00<00:00, 476.39it/s]\u001b[A\n",
      " 52% 456/870 [00:00<00:00, 481.58it/s]\u001b[A\n",
      " 58% 506/870 [00:01<00:00, 486.09it/s]\u001b[A\n",
      " 64% 555/870 [00:01<00:00, 485.69it/s]\u001b[A\n",
      " 69% 604/870 [00:01<00:00, 484.71it/s]\u001b[A\n",
      " 75% 654/870 [00:01<00:00, 488.34it/s]\u001b[A\n",
      " 81% 703/870 [00:01<00:00, 486.73it/s]\u001b[A\n",
      " 87% 753/870 [00:01<00:00, 488.78it/s]\u001b[A\n",
      " 92% 803/870 [00:01<00:00, 490.09it/s]\u001b[A\n",
      "100% 870/870 [00:01<00:00, 489.94it/s]\n",
      "100% 110/110 [00:05<00:00, 19.23it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 23.563218390804597, 'eval_f1': 28.72912968180457, 'epoch': 3.0}\n",
      "Filter: 100% 10570/10570 [00:00<00:00, 37316.75 examples/s]\n",
      "Map (num_proc=2): 100% 452/452 [00:00<00:00, 475.95 examples/s]\n",
      " 96% 55/57 [00:01<00:00, 45.07it/s]\n",
      "  0% 0/452 [00:00<?, ?it/s]\u001b[A\n",
      " 11% 50/452 [00:00<00:00, 494.35it/s]\u001b[A\n",
      " 22% 100/452 [00:00<00:00, 492.93it/s]\u001b[A\n",
      " 33% 150/452 [00:00<00:00, 490.86it/s]\u001b[A\n",
      " 44% 200/452 [00:00<00:00, 468.30it/s]\u001b[A\n",
      " 55% 247/452 [00:00<00:00, 465.78it/s]\u001b[A\n",
      " 65% 295/452 [00:00<00:00, 467.66it/s]\u001b[A\n",
      " 76% 343/452 [00:00<00:00, 469.55it/s]\u001b[A\n",
      " 87% 391/452 [00:00<00:00, 471.06it/s]\u001b[A\n",
      "100% 452/452 [00:00<00:00, 475.15it/s]\n",
      "100% 57/57 [00:03<00:00, 16.88it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 24.557522123893804, 'eval_f1': 29.000371935647273, 'epoch': 3.0}\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m./trained_model_final_1/\u001b[0m at: \u001b[34mhttps://wandb.ai/billiam1100-/huggingface/runs/q3ts92l0\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241201_123917-q3ts92l0/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model_final_1/ --perc_squad 1 --perc_hotpotqa 1 --perc_adversarial_squad 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 3026,
     "status": "ok",
     "timestamp": 1733064055832,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "l6FqOiVfNC9k",
    "outputId": "873a9e9a-ba82-4151-d0eb-c3af01f283e4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/dsc388/Final Project/Repo/trained_model_final_1.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder path and the output zip file name\n",
    "folder_path = os.getcwd()+'/trained_model_final_1'  # Replace with your folder path\n",
    "zip_name = 'trained_model_final_1.zip'  # Specify the desired zip file name\n",
    "\n",
    "for item in os.listdir(folder_path):\n",
    "    item_path = os.path.join(folder_path, item)\n",
    "\n",
    "    # Check if the item is a directory and contains 'checkpoint' in its name\n",
    "    if os.path.isdir(item_path) and 'checkpoint' in item:\n",
    "        # Remove the directory and its contents\n",
    "        shutil.rmtree(item_path)\n",
    "        #print(f\"Deleted folder: {item_path}\")\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(zip_name.replace('.zip', ''), 'zip', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "executionInfo": {
     "elapsed": 99,
     "status": "error",
     "timestamp": 1733064033210,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "F9KDRFOkNOMk",
    "outputId": "1f2d3931-1171-47e4-9fc0-7f6a930d97eb"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/dsc388/Final Project/Repo/trained_model_final'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-de7ca58c0102>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mzip_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'trained_model_final.zip'\u001b[0m  \u001b[0;31m# Specify the desired zip file name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mitem_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/dsc388/Final Project/Repo/trained_model_final'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Specify the folder path and the output zip file name\n",
    "folder_path = os.getcwd()+'/trained_model_final'  # Replace with your folder path\n",
    "zip_name = '/trained_model_final.zip'  # Specify the desired zip file name\n",
    "\n",
    "for item in os.listdir(folder_path):\n",
    "    item_path = os.path.join(folder_path, item)\n",
    "\n",
    "    # Check if the item is a directory and contains 'checkpoint' in its name\n",
    "    if os.path.isdir(item_path) and 'checkpoint' in item:\n",
    "        # Remove the directory and its contents\n",
    "        shutil.rmtree(item_path)\n",
    "        #print(f\"Deleted folder: {item_path}\")\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(zip_name.replace('.zip', ''), 'zip', folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1733063816677,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "glTXpBEEpqfj",
    "outputId": "bb7fbff4-4b6c-491d-bd0e-c7f644109552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebasing (1/1)\r\r\u001b[KSuccessfully rebased and updated refs/heads/final_project_testing.\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eggyhedJpx6P"
   },
   "outputs": [],
   "source": [
    "!git config pull.rebase true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6340,
     "status": "ok",
     "timestamp": 1733064077254,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "aR7VFnaSNatD",
    "outputId": "871ebf53-bb8f-4541-fde6-0c825caaba02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[final_project_testing 0a4dd84] Saved Final Models.\n",
      " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
      " create mode 100644 Final Project/Repo/trained_model_final_1.zip\n",
      "Enumerating objects: 8, done.\n",
      "Counting objects: 100% (8/8), done.\n",
      "Delta compression using up to 12 threads\n",
      "Compressing objects: 100% (5/5), done.\n",
      "Writing objects: 100% (5/5), 48.05 MiB | 17.90 MiB/s, done.\n",
      "Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
      "To https://github.com/WilliamHeidel/dsc388.git\n",
      "   890fe67..0a4dd84  final_project_testing -> final_project_testing\n"
     ]
    }
   ],
   "source": [
    "!git add trained_model_final_1.zip\n",
    "!git config --global user.email \"williamheideljr@gmail.com\"\n",
    "!git config --global user.name \"Billy on Colab\"\n",
    "!git commit -m \"Saved Final Models.\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UwUTd7e_N09z"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHv1TayjZSFM"
   },
   "outputs": [],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_adversarial_qa 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAoCMQKydQOO"
   },
   "outputs": [],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_adversarial_qa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4skvI5PRWUig"
   },
   "outputs": [],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_hotpotqa 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeD2O_ILWZlX"
   },
   "outputs": [],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_hotpotqa 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LROMx9EAWd6B"
   },
   "outputs": [],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_hotpotqa 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgVS2_YvWiMD"
   },
   "outputs": [],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_hotpotqa 0.5 --perc_adversarial_qa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vll9poR0WzL1"
   },
   "outputs": [],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_hotpotqa 0.25 --perc_adversarial_qa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2238592,
     "status": "ok",
     "timestamp": 1732704840046,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "1VzUDC_nW4dX",
    "outputId": "16e87b5d-f9a9-4f45-f90b-76298b66dedc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-27 10:16:05.964870: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 10:16:05.981904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-27 10:16:06.003210: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-27 10:16:06.009590: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-27 10:16:06.024884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 10:16:07.077688: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Preprocessing data... (this takes a little bit, should only happen once per dataset)\n",
      "Map (num_proc=2): 100% 126379/126379 [01:34<00:00, 1333.64 examples/s]\n",
      "\n",
      "Beginning Pipeline!\n",
      "\n",
      "/content/dsc388/Final Project/Repo/helpers.py:277: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `QuestionAnsweringTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n",
      "\n",
      "Beginning Evaluation!\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbilliam1100\u001b[0m (\u001b[33mbilliam1100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/dsc388/Final Project/Repo/wandb/run-20241127_101752-sfle2o8j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./trained_model/\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/billiam1100-/huggingface/runs/sfle2o8j\u001b[0m\n",
      "{'loss': 2.7818, 'grad_norm': 6.337169647216797, 'learning_rate': 4.2803684513529074e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8583, 'grad_norm': 6.991273403167725, 'learning_rate': 3.5607369027058145e-05, 'epoch': 0.86}\n",
      "{'loss': 1.6362, 'grad_norm': 6.503194332122803, 'learning_rate': 2.841105354058722e-05, 'epoch': 1.3}\n",
      "{'loss': 1.5622, 'grad_norm': 5.984935283660889, 'learning_rate': 2.1214738054116294e-05, 'epoch': 1.73}\n",
      "{'loss': 1.4894, 'grad_norm': 6.3004069328308105, 'learning_rate': 1.4018422567645367e-05, 'epoch': 2.16}\n",
      "{'loss': 1.4319, 'grad_norm': 6.180110454559326, 'learning_rate': 6.822107081174439e-06, 'epoch': 2.59}\n",
      "{'train_runtime': 2088.6593, 'train_samples_per_second': 212.897, 'train_steps_per_second': 1.663, 'train_loss': 1.741585353221026, 'epoch': 3.0}\n",
      "100% 3474/3474 [34:47<00:00,  1.66it/s]\n",
      "100% 1329/1329 [00:41<00:00, 46.27it/s]\n",
      "  0% 0/10570 [00:00<?, ?it/s]\u001b[A\n",
      "  1% 53/10570 [00:00<00:20, 525.48it/s]\u001b[A\n",
      "  1% 108/10570 [00:00<00:19, 539.31it/s]\u001b[A\n",
      "  2% 162/10570 [00:00<00:19, 539.30it/s]\u001b[A\n",
      "  2% 216/10570 [00:00<00:19, 536.66it/s]\u001b[A\n",
      "  3% 270/10570 [00:00<00:20, 513.36it/s]\u001b[A\n",
      "  3% 323/10570 [00:00<00:19, 516.72it/s]\u001b[A\n",
      "  4% 378/10570 [00:00<00:19, 524.72it/s]\u001b[A\n",
      "  4% 431/10570 [00:00<00:19, 524.02it/s]\u001b[A\n",
      "  5% 485/10570 [00:00<00:19, 528.41it/s]\u001b[A\n",
      "  5% 540/10570 [00:01<00:18, 534.23it/s]\u001b[A\n",
      "  6% 594/10570 [00:01<00:18, 533.15it/s]\u001b[A\n",
      "  6% 649/10570 [00:01<00:18, 536.46it/s]\u001b[A\n",
      "  7% 704/10570 [00:01<00:18, 538.64it/s]\u001b[A\n",
      "  7% 758/10570 [00:01<00:18, 536.93it/s]\u001b[A\n",
      "  8% 812/10570 [00:01<00:18, 528.35it/s]\u001b[A\n",
      "  8% 865/10570 [00:01<00:18, 527.46it/s]\u001b[A\n",
      "  9% 918/10570 [00:01<00:18, 526.25it/s]\u001b[A\n",
      "  9% 971/10570 [00:01<00:18, 524.67it/s]\u001b[A\n",
      " 10% 1024/10570 [00:01<00:18, 523.48it/s]\u001b[A\n",
      " 10% 1077/10570 [00:02<00:18, 524.43it/s]\u001b[A\n",
      " 11% 1130/10570 [00:02<00:17, 525.01it/s]\u001b[A\n",
      " 11% 1185/10570 [00:02<00:17, 529.83it/s]\u001b[A\n",
      " 12% 1239/10570 [00:02<00:17, 531.29it/s]\u001b[A\n",
      " 12% 1293/10570 [00:02<00:17, 530.89it/s]\u001b[A\n",
      " 13% 1347/10570 [00:02<00:17, 532.08it/s]\u001b[A\n",
      " 13% 1401/10570 [00:02<00:17, 528.12it/s]\u001b[A\n",
      " 14% 1454/10570 [00:02<00:17, 528.29it/s]\u001b[A\n",
      " 14% 1508/10570 [00:02<00:17, 530.64it/s]\u001b[A\n",
      " 15% 1563/10570 [00:02<00:16, 533.53it/s]\u001b[A\n",
      " 15% 1617/10570 [00:03<00:16, 534.22it/s]\u001b[A\n",
      " 16% 1672/10570 [00:03<00:16, 537.06it/s]\u001b[A\n",
      " 16% 1727/10570 [00:03<00:16, 538.24it/s]\u001b[A\n",
      " 17% 1781/10570 [00:03<00:16, 537.87it/s]\u001b[A\n",
      " 17% 1836/10570 [00:03<00:16, 538.72it/s]\u001b[A\n",
      " 18% 1891/10570 [00:03<00:16, 540.17it/s]\u001b[A\n",
      " 18% 1946/10570 [00:03<00:15, 540.17it/s]\u001b[A\n",
      " 19% 2001/10570 [00:03<00:15, 541.51it/s]\u001b[A\n",
      " 19% 2056/10570 [00:03<00:15, 541.51it/s]\u001b[A\n",
      " 20% 2111/10570 [00:03<00:15, 540.54it/s]\u001b[A\n",
      " 20% 2166/10570 [00:04<00:15, 531.15it/s]\u001b[A\n",
      " 21% 2220/10570 [00:04<00:15, 532.25it/s]\u001b[A\n",
      " 22% 2274/10570 [00:04<00:15, 531.20it/s]\u001b[A\n",
      " 22% 2328/10570 [00:04<00:15, 528.99it/s]\u001b[A\n",
      " 23% 2381/10570 [00:04<00:15, 522.19it/s]\u001b[A\n",
      " 23% 2434/10570 [00:04<00:15, 520.83it/s]\u001b[A\n",
      " 24% 2487/10570 [00:04<00:15, 522.28it/s]\u001b[A\n",
      " 24% 2540/10570 [00:04<00:15, 517.18it/s]\u001b[A\n",
      " 25% 2592/10570 [00:04<00:15, 515.07it/s]\u001b[A\n",
      " 25% 2646/10570 [00:04<00:15, 520.06it/s]\u001b[A\n",
      " 26% 2699/10570 [00:05<00:15, 521.96it/s]\u001b[A\n",
      " 26% 2753/10570 [00:05<00:14, 524.96it/s]\u001b[A\n",
      " 27% 2809/10570 [00:05<00:14, 532.92it/s]\u001b[A\n",
      " 27% 2863/10570 [00:05<00:14, 530.27it/s]\u001b[A\n",
      " 28% 2917/10570 [00:05<00:14, 526.87it/s]\u001b[A\n",
      " 28% 2970/10570 [00:05<00:14, 525.18it/s]\u001b[A\n",
      " 29% 3023/10570 [00:05<00:14, 525.07it/s]\u001b[A\n",
      " 29% 3076/10570 [00:05<00:14, 524.57it/s]\u001b[A\n",
      " 30% 3129/10570 [00:05<00:14, 523.52it/s]\u001b[A\n",
      " 30% 3182/10570 [00:06<00:14, 519.90it/s]\u001b[A\n",
      " 31% 3234/10570 [00:06<00:15, 486.14it/s]\u001b[A\n",
      " 31% 3286/10570 [00:06<00:14, 494.63it/s]\u001b[A\n",
      " 32% 3339/10570 [00:06<00:14, 503.01it/s]\u001b[A\n",
      " 32% 3392/10570 [00:06<00:14, 507.88it/s]\u001b[A\n",
      " 33% 3445/10570 [00:06<00:13, 513.66it/s]\u001b[A\n",
      " 33% 3498/10570 [00:06<00:13, 517.02it/s]\u001b[A\n",
      " 34% 3551/10570 [00:06<00:13, 520.51it/s]\u001b[A\n",
      " 34% 3604/10570 [00:06<00:13, 519.90it/s]\u001b[A\n",
      " 35% 3658/10570 [00:06<00:13, 523.02it/s]\u001b[A\n",
      " 35% 3712/10570 [00:07<00:13, 524.72it/s]\u001b[A\n",
      " 36% 3765/10570 [00:07<00:12, 525.89it/s]\u001b[A\n",
      " 36% 3818/10570 [00:07<00:12, 526.24it/s]\u001b[A\n",
      " 37% 3872/10570 [00:07<00:12, 528.17it/s]\u001b[A\n",
      " 37% 3926/10570 [00:07<00:12, 528.97it/s]\u001b[A\n",
      " 38% 3980/10570 [00:07<00:12, 529.43it/s]\u001b[A\n",
      " 38% 4033/10570 [00:07<00:12, 527.56it/s]\u001b[A\n",
      " 39% 4087/10570 [00:07<00:12, 529.88it/s]\u001b[A\n",
      " 39% 4140/10570 [00:07<00:12, 516.34it/s]\u001b[A\n",
      " 40% 4192/10570 [00:08<00:13, 458.65it/s]\u001b[A\n",
      " 40% 4240/10570 [00:08<00:13, 455.50it/s]\u001b[A\n",
      " 41% 4287/10570 [00:08<00:15, 418.03it/s]\u001b[A\n",
      " 41% 4330/10570 [00:08<00:15, 414.15it/s]\u001b[A\n",
      " 41% 4383/10570 [00:08<00:13, 444.50it/s]\u001b[A\n",
      " 42% 4437/10570 [00:08<00:13, 468.86it/s]\u001b[A\n",
      " 42% 4491/10570 [00:08<00:12, 487.09it/s]\u001b[A\n",
      " 43% 4541/10570 [00:08<00:12, 489.36it/s]\u001b[A\n",
      " 43% 4593/10570 [00:08<00:12, 497.01it/s]\u001b[A\n",
      " 44% 4644/10570 [00:08<00:11, 500.27it/s]\u001b[A\n",
      " 44% 4696/10570 [00:09<00:11, 504.58it/s]\u001b[A\n",
      " 45% 4749/10570 [00:09<00:11, 510.57it/s]\u001b[A\n",
      " 45% 4801/10570 [00:09<00:11, 508.71it/s]\u001b[A\n",
      " 46% 4853/10570 [00:09<00:11, 505.89it/s]\u001b[A\n",
      " 46% 4906/10570 [00:09<00:11, 510.38it/s]\u001b[A\n",
      " 47% 4958/10570 [00:09<00:10, 512.61it/s]\u001b[A\n",
      " 47% 5010/10570 [00:09<00:10, 512.14it/s]\u001b[A\n",
      " 48% 5063/10570 [00:09<00:10, 516.55it/s]\u001b[A\n",
      " 48% 5115/10570 [00:09<00:10, 515.42it/s]\u001b[A\n",
      " 49% 5168/10570 [00:09<00:10, 516.81it/s]\u001b[A\n",
      " 49% 5220/10570 [00:10<00:10, 517.57it/s]\u001b[A\n",
      " 50% 5273/10570 [00:10<00:10, 518.34it/s]\u001b[A\n",
      " 50% 5327/10570 [00:10<00:10, 522.33it/s]\u001b[A\n",
      " 51% 5380/10570 [00:10<00:09, 523.15it/s]\u001b[A\n",
      " 51% 5433/10570 [00:10<00:09, 523.74it/s]\u001b[A\n",
      " 52% 5486/10570 [00:10<00:09, 513.62it/s]\u001b[A\n",
      " 52% 5538/10570 [00:10<00:09, 512.69it/s]\u001b[A\n",
      " 53% 5591/10570 [00:10<00:09, 515.18it/s]\u001b[A\n",
      " 53% 5643/10570 [00:10<00:09, 514.77it/s]\u001b[A\n",
      " 54% 5696/10570 [00:11<00:09, 518.16it/s]\u001b[A\n",
      " 54% 5748/10570 [00:11<00:09, 514.72it/s]\u001b[A\n",
      " 55% 5800/10570 [00:11<00:09, 515.45it/s]\u001b[A\n",
      " 55% 5853/10570 [00:11<00:09, 517.87it/s]\u001b[A\n",
      " 56% 5905/10570 [00:11<00:09, 518.05it/s]\u001b[A\n",
      " 56% 5958/10570 [00:11<00:08, 520.16it/s]\u001b[A\n",
      " 57% 6011/10570 [00:11<00:08, 519.02it/s]\u001b[A\n",
      " 57% 6063/10570 [00:11<00:08, 514.12it/s]\u001b[A\n",
      " 58% 6115/10570 [00:11<00:09, 457.84it/s]\u001b[A\n",
      " 58% 6168/10570 [00:11<00:09, 476.95it/s]\u001b[A\n",
      " 59% 6221/10570 [00:12<00:08, 490.24it/s]\u001b[A\n",
      " 59% 6273/10570 [00:12<00:08, 498.60it/s]\u001b[A\n",
      " 60% 6326/10570 [00:12<00:08, 507.22it/s]\u001b[A\n",
      " 60% 6378/10570 [00:12<00:08, 498.51it/s]\u001b[A\n",
      " 61% 6432/10570 [00:12<00:08, 509.68it/s]\u001b[A\n",
      " 61% 6486/10570 [00:12<00:07, 517.98it/s]\u001b[A\n",
      " 62% 6539/10570 [00:12<00:07, 519.50it/s]\u001b[A\n",
      " 62% 6592/10570 [00:12<00:07, 517.65it/s]\u001b[A\n",
      " 63% 6646/10570 [00:12<00:07, 521.50it/s]\u001b[A\n",
      " 63% 6699/10570 [00:12<00:07, 520.94it/s]\u001b[A\n",
      " 64% 6752/10570 [00:13<00:07, 523.33it/s]\u001b[A\n",
      " 64% 6805/10570 [00:13<00:07, 523.93it/s]\u001b[A\n",
      " 65% 6858/10570 [00:13<00:07, 520.21it/s]\u001b[A\n",
      " 65% 6911/10570 [00:13<00:07, 517.97it/s]\u001b[A\n",
      " 66% 6965/10570 [00:13<00:06, 523.48it/s]\u001b[A\n",
      " 66% 7019/10570 [00:13<00:06, 526.20it/s]\u001b[A\n",
      " 67% 7072/10570 [00:13<00:06, 525.49it/s]\u001b[A\n",
      " 67% 7126/10570 [00:13<00:06, 526.94it/s]\u001b[A\n",
      " 68% 7180/10570 [00:13<00:06, 529.23it/s]\u001b[A\n",
      " 68% 7233/10570 [00:13<00:06, 525.43it/s]\u001b[A\n",
      " 69% 7286/10570 [00:14<00:06, 525.07it/s]\u001b[A\n",
      " 69% 7339/10570 [00:14<00:06, 519.03it/s]\u001b[A\n",
      " 70% 7392/10570 [00:14<00:06, 520.61it/s]\u001b[A\n",
      " 70% 7446/10570 [00:14<00:05, 523.87it/s]\u001b[A\n",
      " 71% 7499/10570 [00:14<00:05, 523.52it/s]\u001b[A\n",
      " 71% 7553/10570 [00:14<00:05, 526.32it/s]\u001b[A\n",
      " 72% 7607/10570 [00:14<00:05, 528.57it/s]\u001b[A\n",
      " 72% 7660/10570 [00:14<00:05, 527.99it/s]\u001b[A\n",
      " 73% 7713/10570 [00:14<00:05, 527.11it/s]\u001b[A\n",
      " 73% 7766/10570 [00:15<00:05, 525.12it/s]\u001b[A\n",
      " 74% 7819/10570 [00:15<00:05, 524.99it/s]\u001b[A\n",
      " 74% 7872/10570 [00:15<00:05, 526.44it/s]\u001b[A\n",
      " 75% 7926/10570 [00:15<00:05, 528.47it/s]\u001b[A\n",
      " 75% 7979/10570 [00:15<00:04, 526.90it/s]\u001b[A\n",
      " 76% 8032/10570 [00:15<00:04, 526.99it/s]\u001b[A\n",
      " 76% 8085/10570 [00:15<00:04, 523.36it/s]\u001b[A\n",
      " 77% 8139/10570 [00:15<00:04, 525.97it/s]\u001b[A\n",
      " 78% 8192/10570 [00:15<00:04, 519.00it/s]\u001b[A\n",
      " 78% 8244/10570 [00:15<00:04, 517.87it/s]\u001b[A\n",
      " 78% 8296/10570 [00:16<00:04, 514.64it/s]\u001b[A\n",
      " 79% 8348/10570 [00:16<00:04, 515.38it/s]\u001b[A\n",
      " 79% 8401/10570 [00:16<00:04, 519.37it/s]\u001b[A\n",
      " 80% 8455/10570 [00:16<00:04, 523.19it/s]\u001b[A\n",
      " 80% 8508/10570 [00:16<00:03, 516.69it/s]\u001b[A\n",
      " 81% 8560/10570 [00:16<00:03, 515.41it/s]\u001b[A\n",
      " 81% 8612/10570 [00:16<00:03, 514.26it/s]\u001b[A\n",
      " 82% 8665/10570 [00:16<00:03, 516.40it/s]\u001b[A\n",
      " 82% 8717/10570 [00:16<00:03, 516.66it/s]\u001b[A\n",
      " 83% 8769/10570 [00:16<00:03, 516.21it/s]\u001b[A\n",
      " 83% 8821/10570 [00:17<00:03, 514.80it/s]\u001b[A\n",
      " 84% 8874/10570 [00:17<00:03, 518.93it/s]\u001b[A\n",
      " 84% 8927/10570 [00:17<00:03, 519.84it/s]\u001b[A\n",
      " 85% 8980/10570 [00:17<00:03, 522.37it/s]\u001b[A\n",
      " 85% 9033/10570 [00:17<00:02, 523.05it/s]\u001b[A\n",
      " 86% 9086/10570 [00:17<00:02, 520.41it/s]\u001b[A\n",
      " 86% 9139/10570 [00:17<00:02, 518.40it/s]\u001b[A\n",
      " 87% 9191/10570 [00:17<00:02, 513.98it/s]\u001b[A\n",
      " 87% 9244/10570 [00:17<00:02, 517.85it/s]\u001b[A\n",
      " 88% 9297/10570 [00:17<00:02, 518.78it/s]\u001b[A\n",
      " 88% 9350/10570 [00:18<00:02, 519.42it/s]\u001b[A\n",
      " 89% 9403/10570 [00:18<00:02, 521.07it/s]\u001b[A\n",
      " 89% 9456/10570 [00:18<00:02, 520.08it/s]\u001b[A\n",
      " 90% 9509/10570 [00:18<00:02, 518.82it/s]\u001b[A\n",
      " 90% 9563/10570 [00:18<00:01, 524.45it/s]\u001b[A\n",
      " 91% 9616/10570 [00:18<00:01, 525.63it/s]\u001b[A\n",
      " 91% 9669/10570 [00:18<00:01, 524.64it/s]\u001b[A\n",
      " 92% 9723/10570 [00:18<00:01, 528.64it/s]\u001b[A\n",
      " 92% 9776/10570 [00:18<00:01, 526.38it/s]\u001b[A\n",
      " 93% 9829/10570 [00:18<00:01, 525.13it/s]\u001b[A\n",
      " 93% 9882/10570 [00:19<00:01, 523.69it/s]\u001b[A\n",
      " 94% 9935/10570 [00:19<00:01, 520.55it/s]\u001b[A\n",
      " 94% 9988/10570 [00:19<00:01, 520.89it/s]\u001b[A\n",
      " 95% 10042/10570 [00:19<00:01, 524.09it/s]\u001b[A\n",
      " 96% 10095/10570 [00:19<00:00, 523.14it/s]\u001b[A\n",
      " 96% 10148/10570 [00:19<00:00, 524.71it/s]\u001b[A\n",
      " 97% 10201/10570 [00:19<00:00, 522.90it/s]\u001b[A\n",
      " 97% 10254/10570 [00:19<00:00, 523.32it/s]\u001b[A\n",
      " 98% 10307/10570 [00:19<00:00, 521.62it/s]\u001b[A\n",
      " 98% 10360/10570 [00:19<00:00, 523.03it/s]\u001b[A\n",
      " 99% 10413/10570 [00:20<00:00, 520.94it/s]\u001b[A\n",
      " 99% 10466/10570 [00:20<00:00, 518.46it/s]\u001b[A\n",
      "100% 10570/10570 [00:20<00:00, 518.41it/s]\n",
      "100% 1329/1329 [01:05<00:00, 20.18it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 75.41154210028382, 'eval_f1': 83.77024880953252, 'epoch': 3.0}\n",
      " 96% 106/110 [00:02<00:00, 46.25it/s]\n",
      "  0% 0/870 [00:00<?, ?it/s]\u001b[A\n",
      "  6% 52/870 [00:00<00:01, 508.04it/s]\u001b[A\n",
      " 12% 104/870 [00:00<00:01, 514.70it/s]\u001b[A\n",
      " 18% 156/870 [00:00<00:01, 516.22it/s]\u001b[A\n",
      " 24% 209/870 [00:00<00:01, 520.61it/s]\u001b[A\n",
      " 30% 262/870 [00:00<00:01, 519.27it/s]\u001b[A\n",
      " 36% 314/870 [00:00<00:01, 519.07it/s]\u001b[A\n",
      " 42% 366/870 [00:00<00:00, 517.99it/s]\u001b[A\n",
      " 48% 418/870 [00:00<00:00, 503.57it/s]\u001b[A\n",
      " 54% 469/870 [00:00<00:00, 504.79it/s]\u001b[A\n",
      " 60% 520/870 [00:01<00:00, 503.19it/s]\u001b[A\n",
      " 66% 571/870 [00:01<00:00, 495.59it/s]\u001b[A\n",
      " 71% 621/870 [00:01<00:00, 493.24it/s]\u001b[A\n",
      " 77% 672/870 [00:01<00:00, 496.07it/s]\u001b[A\n",
      " 83% 724/870 [00:01<00:00, 502.15it/s]\u001b[A\n",
      " 89% 775/870 [00:01<00:00, 484.81it/s]\u001b[A\n",
      "100% 870/870 [00:01<00:00, 503.61it/s]\n",
      "100% 110/110 [00:05<00:00, 19.89it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 15.28735632183908, 'eval_f1': 21.261702942357978, 'epoch': 3.0}\n",
      " 98% 56/57 [00:01<00:00, 46.41it/s]\n",
      "  0% 0/452 [00:00<?, ?it/s]\u001b[A\n",
      " 12% 52/452 [00:00<00:00, 514.04it/s]\u001b[A\n",
      " 23% 104/452 [00:00<00:00, 514.72it/s]\u001b[A\n",
      " 35% 156/452 [00:00<00:00, 514.06it/s]\u001b[A\n",
      " 46% 208/452 [00:00<00:00, 514.08it/s]\u001b[A\n",
      " 58% 260/452 [00:00<00:00, 505.87it/s]\u001b[A\n",
      " 69% 311/452 [00:00<00:00, 503.14it/s]\u001b[A\n",
      " 80% 362/452 [00:00<00:00, 504.44it/s]\u001b[A\n",
      "100% 452/452 [00:00<00:00, 508.37it/s]\n",
      "100% 57/57 [00:02<00:00, 19.96it/s]\n",
      "Evaluation results:\n",
      "{'eval_exact_match': 18.58407079646018, 'eval_f1': 23.921126122128204, 'epoch': 3.0}\n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33m./trained_model/\u001b[0m at: \u001b[34mhttps://wandb.ai/billiam1100-/huggingface/runs/sfle2o8j\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20241127_101752-sfle2o8j/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 run.py --dataset squad --per_device_train_batch_size 128 --do_train --do_eval --task qa --eval_tough_examples --output_dir ./trained_model/ --perc_squad 1 --perc_hotpotqa 0.1 --perc_adversarial_qa 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1806,
     "status": "ok",
     "timestamp": 1733243618688,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "Wu09lehpVHF8"
   },
   "outputs": [],
   "source": [
    "!git add Results_Fixed_Test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1733243618952,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "nWUMYfkJVkD7"
   },
   "outputs": [],
   "source": [
    "!git config --global user.email \"williamheideljr@gmail.com\"\n",
    "!git config --global user.name \"Billy on Colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1733243621072,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "U97javRdVaDv",
    "outputId": "2070cb40-1127-4ea8-9971-534349db3262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[final_project_testing b2e1298] Added more predictions to squad.\n",
      " 12 files changed, 23790 insertions(+)\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_metrics_sq1.0_as1.0_adv0_hp0_.json\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_metrics_sq1.0_as1.0_adv0_hp0__tough.json\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_metrics_sq1.0_as1.0_adv0_hp0__tough_entities.json\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_metrics_sq1.0_as2.0_adv0_hp0_.json\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_metrics_sq1.0_as2.0_adv0_hp0__tough.json\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_metrics_sq1.0_as2.0_adv0_hp0__tough_entities.json\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_predictions_sq1.0_as1.0_adv0_hp0_.jsonl\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_predictions_sq1.0_as1.0_adv0_hp0__tough.jsonl\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_predictions_sq1.0_as1.0_adv0_hp0__tough_entities.jsonl\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_predictions_sq1.0_as2.0_adv0_hp0_.jsonl\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_predictions_sq1.0_as2.0_adv0_hp0__tough.jsonl\n",
      " create mode 100644 Final Project/Repo/Results_Fixed_Test/eval_predictions_sq1.0_as2.0_adv0_hp0__tough_entities.jsonl\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Added more predictions to squad.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2003,
     "status": "ok",
     "timestamp": 1733243625177,
     "user": {
      "displayName": "William Heidel",
      "userId": "07062568246869281472"
     },
     "user_tz": 300
    },
    "id": "C1gGjrpDVssL",
    "outputId": "66e207bd-8822-4abb-c1d1-460d64f68af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 21, done.\n",
      "Counting objects:   4% (1/21)\rCounting objects:   9% (2/21)\rCounting objects:  14% (3/21)\rCounting objects:  19% (4/21)\rCounting objects:  23% (5/21)\rCounting objects:  28% (6/21)\rCounting objects:  33% (7/21)\rCounting objects:  38% (8/21)\rCounting objects:  42% (9/21)\rCounting objects:  47% (10/21)\rCounting objects:  52% (11/21)\rCounting objects:  57% (12/21)\rCounting objects:  61% (13/21)\rCounting objects:  66% (14/21)\rCounting objects:  71% (15/21)\rCounting objects:  76% (16/21)\rCounting objects:  80% (17/21)\rCounting objects:  85% (18/21)\rCounting objects:  90% (19/21)\rCounting objects:  95% (20/21)\rCounting objects: 100% (21/21)\rCounting objects: 100% (21/21), done.\n",
      "Delta compression using up to 12 threads\n",
      "Compressing objects: 100% (17/17), done.\n",
      "Writing objects: 100% (17/17), 1.47 MiB | 1.93 MiB/s, done.\n",
      "Total 17 (delta 8), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (8/8), completed with 4 local objects.\u001b[K\n",
      "To https://github.com/WilliamHeidel/dsc388.git\n",
      "   3088860..b2e1298  final_project_testing -> final_project_testing\n"
     ]
    }
   ],
   "source": [
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV5shP5b2zSa"
   },
   "source": [
    "## 7. Update code and retrain\n",
    "\n",
    "Here there are two options -\n",
    "\n",
    "### Option 1: Code on your local machine\n",
    "\n",
    "* Modify your code locally\n",
    "* Push to Github from your machine\n",
    "* Pull on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tj4vnJWrADPy"
   },
   "outputs": [],
   "source": [
    "#!git pull origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5c20gZfnBNh"
   },
   "outputs": [],
   "source": [
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
